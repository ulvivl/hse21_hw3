{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "hse21_HW3-2.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "7DFpK_Pf1hAX",
        "0fTXUIiw2WGQ",
        "XiVlP4mfy74q"
      ]
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3rFZS5A_yy1o"
      },
      "source": [
        "# Подготовка файлов и программ"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7DFpK_Pf1hAX"
      },
      "source": [
        "## Установка HISAT2 (для выравниваия RNA-seq чтений на геном)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WS21uIX63ehw",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ac98902f-6101-4bbe-fe71-b174cc7f1de1"
      },
      "source": [
        "!apt-get update"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\r0% [Working]\r            \rGet:1 http://security.ubuntu.com/ubuntu bionic-security InRelease [88.7 kB]\n",
            "\r0% [Connecting to archive.ubuntu.com (91.189.88.152)] [1 InRelease 14.2 kB/88.7\r                                                                               \rGet:2 https://cloud.r-project.org/bin/linux/ubuntu bionic-cran40/ InRelease [3,626 B]\n",
            "\r0% [Connecting to archive.ubuntu.com (91.189.88.152)] [1 InRelease 31.5 kB/88.7\r0% [Connecting to archive.ubuntu.com (91.189.88.152)] [1 InRelease 43.1 kB/88.7\r0% [2 InRelease gpgv 3,626 B] [Connecting to archive.ubuntu.com (91.189.88.152)\r0% [2 InRelease gpgv 3,626 B] [Waiting for headers] [Waiting for headers] [Wait\r                                                                               \rIgn:3 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64  InRelease\n",
            "\r0% [2 InRelease gpgv 3,626 B] [Waiting for headers] [Waiting for headers] [Wait\r                                                                               \rGet:4 http://ppa.launchpad.net/c2d4u.team/c2d4u4.0+/ubuntu bionic InRelease [15.9 kB]\n",
            "\r0% [2 InRelease gpgv 3,626 B] [Waiting for headers] [4 InRelease 2,572 B/15.9 k\r                                                                               \rIgn:5 https://developer.download.nvidia.com/compute/machine-learning/repos/ubuntu1804/x86_64  InRelease\n",
            "\r0% [2 InRelease gpgv 3,626 B] [Waiting for headers] [4 InRelease 11.3 kB/15.9 k\r                                                                               \rGet:6 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64  Release [696 B]\n",
            "Hit:7 https://developer.download.nvidia.com/compute/machine-learning/repos/ubuntu1804/x86_64  Release\n",
            "Hit:8 http://archive.ubuntu.com/ubuntu bionic InRelease\n",
            "Get:9 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64  Release.gpg [836 B]\n",
            "Get:10 http://archive.ubuntu.com/ubuntu bionic-updates InRelease [88.7 kB]\n",
            "Hit:11 http://ppa.launchpad.net/cran/libgit2/ubuntu bionic InRelease\n",
            "Hit:12 http://ppa.launchpad.net/deadsnakes/ppa/ubuntu bionic InRelease\n",
            "Get:13 http://archive.ubuntu.com/ubuntu bionic-backports InRelease [74.6 kB]\n",
            "Get:14 http://security.ubuntu.com/ubuntu bionic-security/main amd64 Packages [2,450 kB]\n",
            "Hit:15 http://ppa.launchpad.net/graphics-drivers/ppa/ubuntu bionic InRelease\n",
            "Get:16 http://security.ubuntu.com/ubuntu bionic-security/universe amd64 Packages [1,444 kB]\n",
            "Get:17 http://security.ubuntu.com/ubuntu bionic-security/restricted amd64 Packages [687 kB]\n",
            "Get:19 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64  Packages [829 kB]\n",
            "Get:20 http://ppa.launchpad.net/c2d4u.team/c2d4u4.0+/ubuntu bionic/main Sources [1,813 kB]\n",
            "Get:21 http://archive.ubuntu.com/ubuntu bionic-updates/universe amd64 Packages [2,225 kB]\n",
            "Get:22 http://ppa.launchpad.net/c2d4u.team/c2d4u4.0+/ubuntu bionic/main amd64 Packages [930 kB]\n",
            "Get:23 http://archive.ubuntu.com/ubuntu bionic-updates/main amd64 Packages [2,894 kB]\n",
            "Get:24 http://archive.ubuntu.com/ubuntu bionic-updates/restricted amd64 Packages [721 kB]\n",
            "Fetched 14.3 MB in 4s (3,665 kB/s)\n",
            "Reading package lists... Done\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3md6cslv3is6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ae0c258b-da9e-428c-f819-5a0660c14392"
      },
      "source": [
        "!apt-get install hisat2"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Reading package lists... Done\n",
            "Building dependency tree       \n",
            "Reading state information... Done\n",
            "The following NEW packages will be installed:\n",
            "  hisat2\n",
            "0 upgraded, 1 newly installed, 0 to remove and 42 not upgraded.\n",
            "Need to get 1,278 kB of archives.\n",
            "After this operation, 5,144 kB of additional disk space will be used.\n",
            "Get:1 http://archive.ubuntu.com/ubuntu bionic/universe amd64 hisat2 amd64 2.1.0-1 [1,278 kB]\n",
            "Fetched 1,278 kB in 1s (1,291 kB/s)\n",
            "Selecting previously unselected package hisat2.\n",
            "(Reading database ... 155222 files and directories currently installed.)\n",
            "Preparing to unpack .../hisat2_2.1.0-1_amd64.deb ...\n",
            "Unpacking hisat2 (2.1.0-1) ...\n",
            "Setting up hisat2 (2.1.0-1) ...\n",
            "Processing triggers for man-db (2.8.3-2ubuntu0.1) ...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6-Eyz3aD3m8-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e43189ac-8ea5-42b3-888b-f05defa52c87"
      },
      "source": [
        "!hisat2 --version"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/usr/bin/hisat2-align-s version 2.1.0\n",
            "64-bit\n",
            "Built on Debian unstable\n",
            "Mon Sep  4 12:49:40 UTC 2017\n",
            "Compiler: gcc version 7.2.0 (Ubuntu 7.2.0-12ubuntu1) \n",
            "Options: -O3   -funroll-loops -g3 -Wdate-time -D_FORTIFY_SOURCE=2 -DPOPCNT_CAPABILITY\n",
            "Sizeof {int, long, long long, void*, size_t, off_t}: {4, 8, 8, 8, 8, 8}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0fTXUIiw2WGQ"
      },
      "source": [
        "## Установка sra-toolkit (для скачивания .fastq файлов из NCBI)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5m-7wf_x2Yue",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2a96db84-c21a-419e-9e65-a112e8cd7ebc"
      },
      "source": [
        "!apt-get install sra-toolkit"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Reading package lists... Done\n",
            "Building dependency tree       \n",
            "Reading state information... Done\n",
            "The following additional packages will be installed:\n",
            "  blends-common libkdf5-2 libmagic-mgc libmagic1 libmbedcrypto1 libmbedtls10\n",
            "  libncbi-vdb2 libncbi-wvdb2 med-config menu\n",
            "Suggested packages:\n",
            "  blends-doc file menu-l10n gksu | kde-runtime | ktsuss\n",
            "The following NEW packages will be installed:\n",
            "  blends-common libkdf5-2 libmagic-mgc libmagic1 libmbedcrypto1 libmbedtls10\n",
            "  libncbi-vdb2 libncbi-wvdb2 med-config menu sra-toolkit\n",
            "0 upgraded, 11 newly installed, 0 to remove and 42 not upgraded.\n",
            "Need to get 4,042 kB of archives.\n",
            "After this operation, 22.6 MB of additional disk space will be used.\n",
            "Get:1 http://archive.ubuntu.com/ubuntu bionic-updates/main amd64 libmagic-mgc amd64 1:5.32-2ubuntu0.4 [184 kB]\n",
            "Get:2 http://archive.ubuntu.com/ubuntu bionic-updates/main amd64 libmagic1 amd64 1:5.32-2ubuntu0.4 [68.6 kB]\n",
            "Get:3 http://archive.ubuntu.com/ubuntu bionic-updates/universe amd64 menu amd64 2.1.47ubuntu2.1 [349 kB]\n",
            "Get:4 http://archive.ubuntu.com/ubuntu bionic/universe amd64 blends-common all 0.6.100ubuntu2 [15.0 kB]\n",
            "Get:5 http://archive.ubuntu.com/ubuntu bionic/universe amd64 libkdf5-2 amd64 2.8.2-2+dfsg-1build1 [13.1 kB]\n",
            "Get:6 http://archive.ubuntu.com/ubuntu bionic/universe amd64 libmbedcrypto1 amd64 2.8.0-1 [140 kB]\n",
            "Get:7 http://archive.ubuntu.com/ubuntu bionic/universe amd64 libmbedtls10 amd64 2.8.0-1 [66.8 kB]\n",
            "Get:8 http://archive.ubuntu.com/ubuntu bionic/universe amd64 libncbi-vdb2 amd64 2.8.2-2+dfsg-1build1 [1,098 kB]\n",
            "Get:9 http://archive.ubuntu.com/ubuntu bionic/universe amd64 libncbi-wvdb2 amd64 2.8.2-2+dfsg-1build1 [997 kB]\n",
            "Get:10 http://archive.ubuntu.com/ubuntu bionic/universe amd64 sra-toolkit amd64 2.8.2-5+dfsg-1 [1,102 kB]\n",
            "Get:11 http://archive.ubuntu.com/ubuntu bionic/universe amd64 med-config all 3.0.1ubuntu1 [9,404 B]\n",
            "Fetched 4,042 kB in 1s (3,198 kB/s)\n",
            "Preconfiguring packages ...\n",
            "Selecting previously unselected package libmagic-mgc.\n",
            "(Reading database ... 155244 files and directories currently installed.)\n",
            "Preparing to unpack .../00-libmagic-mgc_1%3a5.32-2ubuntu0.4_amd64.deb ...\n",
            "Unpacking libmagic-mgc (1:5.32-2ubuntu0.4) ...\n",
            "Selecting previously unselected package libmagic1:amd64.\n",
            "Preparing to unpack .../01-libmagic1_1%3a5.32-2ubuntu0.4_amd64.deb ...\n",
            "Unpacking libmagic1:amd64 (1:5.32-2ubuntu0.4) ...\n",
            "Selecting previously unselected package menu.\n",
            "Preparing to unpack .../02-menu_2.1.47ubuntu2.1_amd64.deb ...\n",
            "Unpacking menu (2.1.47ubuntu2.1) ...\n",
            "Selecting previously unselected package blends-common.\n",
            "Preparing to unpack .../03-blends-common_0.6.100ubuntu2_all.deb ...\n",
            "Unpacking blends-common (0.6.100ubuntu2) ...\n",
            "Selecting previously unselected package libkdf5-2.\n",
            "Preparing to unpack .../04-libkdf5-2_2.8.2-2+dfsg-1build1_amd64.deb ...\n",
            "Unpacking libkdf5-2 (2.8.2-2+dfsg-1build1) ...\n",
            "Selecting previously unselected package libmbedcrypto1:amd64.\n",
            "Preparing to unpack .../05-libmbedcrypto1_2.8.0-1_amd64.deb ...\n",
            "Unpacking libmbedcrypto1:amd64 (2.8.0-1) ...\n",
            "Selecting previously unselected package libmbedtls10:amd64.\n",
            "Preparing to unpack .../06-libmbedtls10_2.8.0-1_amd64.deb ...\n",
            "Unpacking libmbedtls10:amd64 (2.8.0-1) ...\n",
            "Selecting previously unselected package libncbi-vdb2.\n",
            "Preparing to unpack .../07-libncbi-vdb2_2.8.2-2+dfsg-1build1_amd64.deb ...\n",
            "Unpacking libncbi-vdb2 (2.8.2-2+dfsg-1build1) ...\n",
            "Selecting previously unselected package libncbi-wvdb2.\n",
            "Preparing to unpack .../08-libncbi-wvdb2_2.8.2-2+dfsg-1build1_amd64.deb ...\n",
            "Unpacking libncbi-wvdb2 (2.8.2-2+dfsg-1build1) ...\n",
            "Selecting previously unselected package sra-toolkit.\n",
            "Preparing to unpack .../09-sra-toolkit_2.8.2-5+dfsg-1_amd64.deb ...\n",
            "Unpacking sra-toolkit (2.8.2-5+dfsg-1) ...\n",
            "Selecting previously unselected package med-config.\n",
            "Preparing to unpack .../10-med-config_3.0.1ubuntu1_all.deb ...\n",
            "Unpacking med-config (3.0.1ubuntu1) ...\n",
            "Setting up libmbedcrypto1:amd64 (2.8.0-1) ...\n",
            "Setting up menu (2.1.47ubuntu2.1) ...\n",
            "Setting up libkdf5-2 (2.8.2-2+dfsg-1build1) ...\n",
            "Setting up libmagic-mgc (1:5.32-2ubuntu0.4) ...\n",
            "Setting up libmagic1:amd64 (1:5.32-2ubuntu0.4) ...\n",
            "Setting up libncbi-wvdb2 (2.8.2-2+dfsg-1build1) ...\n",
            "Setting up libmbedtls10:amd64 (2.8.0-1) ...\n",
            "Setting up blends-common (0.6.100ubuntu2) ...\n",
            "Setting up libncbi-vdb2 (2.8.2-2+dfsg-1build1) ...\n",
            "Setting up sra-toolkit (2.8.2-5+dfsg-1) ...\n",
            "Setting up med-config (3.0.1ubuntu1) ...\n",
            "Adding group `med' (GID 109) ...\n",
            "Done.\n",
            "Processing triggers for man-db (2.8.3-2ubuntu0.1) ...\n",
            "Processing triggers for libc-bin (2.27-3ubuntu1.3) ...\n",
            "/sbin/ldconfig.real: /usr/local/lib/python3.7/dist-packages/ideep4py/lib/libmkldnn.so.0 is not a symbolic link\n",
            "\n",
            "Processing triggers for menu (2.1.47ubuntu2.1) ...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XiVlP4mfy74q"
      },
      "source": [
        "## Установка FastQC"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "62l1Q2ymbENA",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "12c9c30d-57b0-426a-8f98-80d8a9ae81f9"
      },
      "source": [
        "!java -version"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "openjdk version \"11.0.11\" 2021-04-20\n",
            "OpenJDK Runtime Environment (build 11.0.11+9-Ubuntu-0ubuntu2.18.04)\n",
            "OpenJDK 64-Bit Server VM (build 11.0.11+9-Ubuntu-0ubuntu2.18.04, mixed mode, sharing)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8bpgwFgcbgRd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b5552a57-e20b-4d9d-8adb-bebbd6c373b3"
      },
      "source": [
        "!wget https://www.bioinformatics.babraham.ac.uk/projects/fastqc/fastqc_v0.11.9.zip"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2021-12-01 06:46:14--  https://www.bioinformatics.babraham.ac.uk/projects/fastqc/fastqc_v0.11.9.zip\n",
            "Resolving www.bioinformatics.babraham.ac.uk (www.bioinformatics.babraham.ac.uk)... 149.155.133.4\n",
            "Connecting to www.bioinformatics.babraham.ac.uk (www.bioinformatics.babraham.ac.uk)|149.155.133.4|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 10249221 (9.8M) [application/zip]\n",
            "Saving to: ‘fastqc_v0.11.9.zip’\n",
            "\n",
            "fastqc_v0.11.9.zip  100%[===================>]   9.77M  4.08MB/s    in 2.4s    \n",
            "\n",
            "2021-12-01 06:46:17 (4.08 MB/s) - ‘fastqc_v0.11.9.zip’ saved [10249221/10249221]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yTcTjOTJblcm",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6d31be0c-a5d1-49a8-85ab-79617c2450c8"
      },
      "source": [
        "!unzip fastqc_v0.11.9.zip"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Archive:  fastqc_v0.11.9.zip\n",
            "  inflating: FastQC/cisd-jhdf5.jar   \n",
            "   creating: FastQC/Configuration/\n",
            "  inflating: FastQC/Configuration/adapter_list.txt  \n",
            "  inflating: FastQC/Configuration/contaminant_list.txt  \n",
            "  inflating: FastQC/Configuration/limits.txt  \n",
            "  inflating: FastQC/fastqc           \n",
            "  inflating: FastQC/fastqc_icon.ico  \n",
            "   creating: FastQC/Help/\n",
            "   creating: FastQC/Help/1 Introduction/\n",
            "   creating: FastQC/Help/1 Introduction/.svn/\n",
            "  inflating: FastQC/Help/1 Introduction/.svn/entries  \n",
            "   creating: FastQC/Help/1 Introduction/.svn/props/\n",
            "   creating: FastQC/Help/1 Introduction/.svn/text-base/\n",
            "  inflating: FastQC/Help/1 Introduction/.svn/text-base/1.1 What is FastQC.html.svn-base  \n",
            "   creating: FastQC/Help/1 Introduction/.svn/tmp/\n",
            "   creating: FastQC/Help/1 Introduction/.svn/tmp/props/\n",
            "  inflating: FastQC/Help/1 Introduction/1.1 What is FastQC.html  \n",
            "   creating: FastQC/Help/2 Basic Operations/\n",
            "   creating: FastQC/Help/2 Basic Operations/.svn/\n",
            "  inflating: FastQC/Help/2 Basic Operations/.svn/entries  \n",
            "   creating: FastQC/Help/2 Basic Operations/.svn/props/\n",
            "   creating: FastQC/Help/2 Basic Operations/.svn/text-base/\n",
            "  inflating: FastQC/Help/2 Basic Operations/.svn/text-base/2.1 Opening a sequence file.html.svn-base  \n",
            "  inflating: FastQC/Help/2 Basic Operations/.svn/text-base/2.2 Evaluating Results.html.svn-base  \n",
            "  inflating: FastQC/Help/2 Basic Operations/.svn/text-base/2.3 Saving a Report.html.svn-base  \n",
            "   creating: FastQC/Help/2 Basic Operations/.svn/tmp/\n",
            "   creating: FastQC/Help/2 Basic Operations/.svn/tmp/props/\n",
            "  inflating: FastQC/Help/2 Basic Operations/2.1 Opening a sequence file.html  \n",
            "  inflating: FastQC/Help/2 Basic Operations/2.2 Evaluating Results.html  \n",
            "  inflating: FastQC/Help/2 Basic Operations/2.3 Saving a Report.html  \n",
            "   creating: FastQC/Help/3 Analysis Modules/\n",
            "   creating: FastQC/Help/3 Analysis Modules/.svn/\n",
            "  inflating: FastQC/Help/3 Analysis Modules/.svn/entries  \n",
            "   creating: FastQC/Help/3 Analysis Modules/.svn/prop-base/\n",
            " extracting: FastQC/Help/3 Analysis Modules/.svn/prop-base/duplication_levels.png.svn-base  \n",
            "  inflating: FastQC/Help/3 Analysis Modules/.svn/prop-base/kmer_profiles.png.svn-base  \n",
            " extracting: FastQC/Help/3 Analysis Modules/.svn/prop-base/per_base_gc_content.png.svn-base  \n",
            " extracting: FastQC/Help/3 Analysis Modules/.svn/prop-base/per_base_n_content.png.svn-base  \n",
            " extracting: FastQC/Help/3 Analysis Modules/.svn/prop-base/per_base_quality.png.svn-base  \n",
            " extracting: FastQC/Help/3 Analysis Modules/.svn/prop-base/per_base_sequence_content.png.svn-base  \n",
            " extracting: FastQC/Help/3 Analysis Modules/.svn/prop-base/per_sequence_gc_content.png.svn-base  \n",
            " extracting: FastQC/Help/3 Analysis Modules/.svn/prop-base/per_sequence_quality.png.svn-base  \n",
            " extracting: FastQC/Help/3 Analysis Modules/.svn/prop-base/per_tile_quality.png.svn-base  \n",
            " extracting: FastQC/Help/3 Analysis Modules/.svn/prop-base/sequence_length_distribution.png.svn-base  \n",
            "   creating: FastQC/Help/3 Analysis Modules/.svn/props/\n",
            "   creating: FastQC/Help/3 Analysis Modules/.svn/text-base/\n",
            "  inflating: FastQC/Help/3 Analysis Modules/.svn/text-base/1 Basic Statistics.html.svn-base  \n",
            "  inflating: FastQC/Help/3 Analysis Modules/.svn/text-base/10 Adapter Content.html.svn-base  \n",
            "  inflating: FastQC/Help/3 Analysis Modules/.svn/text-base/11 Kmer Content.html.svn-base  \n",
            "  inflating: FastQC/Help/3 Analysis Modules/.svn/text-base/12 Per Tile Sequence Quality.html.svn-base  \n",
            "  inflating: FastQC/Help/3 Analysis Modules/.svn/text-base/2 Per Base Sequence Quality.html.svn-base  \n",
            "  inflating: FastQC/Help/3 Analysis Modules/.svn/text-base/3 Per Sequence Quality Scores.html.svn-base  \n",
            "  inflating: FastQC/Help/3 Analysis Modules/.svn/text-base/4 Per Base Sequence Content.html.svn-base  \n",
            "  inflating: FastQC/Help/3 Analysis Modules/.svn/text-base/5 Per Sequence GC Content.html.svn-base  \n",
            "  inflating: FastQC/Help/3 Analysis Modules/.svn/text-base/6 Per Base N Content.html.svn-base  \n",
            "  inflating: FastQC/Help/3 Analysis Modules/.svn/text-base/7 Sequence Length Distribution.html.svn-base  \n",
            "  inflating: FastQC/Help/3 Analysis Modules/.svn/text-base/8 Duplicate Sequences.html.svn-base  \n",
            "  inflating: FastQC/Help/3 Analysis Modules/.svn/text-base/9 Overrepresented Sequences.html.svn-base  \n",
            "  inflating: FastQC/Help/3 Analysis Modules/.svn/text-base/duplication_levels.png.svn-base  \n",
            "  inflating: FastQC/Help/3 Analysis Modules/.svn/text-base/kmer_profiles.png.svn-base  \n",
            "  inflating: FastQC/Help/3 Analysis Modules/.svn/text-base/per_base_gc_content.png.svn-base  \n",
            "  inflating: FastQC/Help/3 Analysis Modules/.svn/text-base/per_base_n_content.png.svn-base  \n",
            "  inflating: FastQC/Help/3 Analysis Modules/.svn/text-base/per_base_quality.png.svn-base  \n",
            "  inflating: FastQC/Help/3 Analysis Modules/.svn/text-base/per_base_sequence_content.png.svn-base  \n",
            "  inflating: FastQC/Help/3 Analysis Modules/.svn/text-base/per_sequence_gc_content.png.svn-base  \n",
            "  inflating: FastQC/Help/3 Analysis Modules/.svn/text-base/per_sequence_quality.png.svn-base  \n",
            "  inflating: FastQC/Help/3 Analysis Modules/.svn/text-base/per_tile_quality.png.svn-base  \n",
            "  inflating: FastQC/Help/3 Analysis Modules/.svn/text-base/sequence_length_distribution.png.svn-base  \n",
            "   creating: FastQC/Help/3 Analysis Modules/.svn/tmp/\n",
            "   creating: FastQC/Help/3 Analysis Modules/.svn/tmp/props/\n",
            "  inflating: FastQC/Help/3 Analysis Modules/1 Basic Statistics.html  \n",
            "  inflating: FastQC/Help/3 Analysis Modules/10 Adapter Content.html  \n",
            "  inflating: FastQC/Help/3 Analysis Modules/11 Kmer Content.html  \n",
            "  inflating: FastQC/Help/3 Analysis Modules/12 Per Tile Sequence Quality.html  \n",
            "  inflating: FastQC/Help/3 Analysis Modules/2 Per Base Sequence Quality.html  \n",
            "  inflating: FastQC/Help/3 Analysis Modules/3 Per Sequence Quality Scores.html  \n",
            "  inflating: FastQC/Help/3 Analysis Modules/4 Per Base Sequence Content.html  \n",
            "  inflating: FastQC/Help/3 Analysis Modules/5 Per Sequence GC Content.html  \n",
            "  inflating: FastQC/Help/3 Analysis Modules/6 Per Base N Content.html  \n",
            "  inflating: FastQC/Help/3 Analysis Modules/7 Sequence Length Distribution.html  \n",
            "  inflating: FastQC/Help/3 Analysis Modules/8 Duplicate Sequences.html  \n",
            "  inflating: FastQC/Help/3 Analysis Modules/9 Overrepresented Sequences.html  \n",
            "  inflating: FastQC/Help/3 Analysis Modules/duplication_levels.png  \n",
            "  inflating: FastQC/Help/3 Analysis Modules/kmer_profiles.png  \n",
            "  inflating: FastQC/Help/3 Analysis Modules/per_base_gc_content.png  \n",
            "  inflating: FastQC/Help/3 Analysis Modules/per_base_n_content.png  \n",
            "  inflating: FastQC/Help/3 Analysis Modules/per_base_quality.png  \n",
            "  inflating: FastQC/Help/3 Analysis Modules/per_base_sequence_content.png  \n",
            "  inflating: FastQC/Help/3 Analysis Modules/per_sequence_gc_content.png  \n",
            "  inflating: FastQC/Help/3 Analysis Modules/per_sequence_quality.png  \n",
            "  inflating: FastQC/Help/3 Analysis Modules/per_tile_quality.png  \n",
            "  inflating: FastQC/Help/3 Analysis Modules/sequence_length_distribution.png  \n",
            "  inflating: FastQC/INSTALL.txt      \n",
            "  inflating: FastQC/jbzip2-0.9.jar   \n",
            "  inflating: FastQC/LICENSE          \n",
            "  inflating: FastQC/LICENSE.txt      \n",
            "  inflating: FastQC/LICENSE_JHDF5.txt  \n",
            "   creating: FastQC/net/\n",
            "   creating: FastQC/net/sourceforge/\n",
            "   creating: FastQC/net/sourceforge/iharder/\n",
            "   creating: FastQC/net/sourceforge/iharder/base64/\n",
            "  inflating: FastQC/net/sourceforge/iharder/base64/Base64$1.class  \n",
            "  inflating: FastQC/net/sourceforge/iharder/base64/Base64$InputStream.class  \n",
            "  inflating: FastQC/net/sourceforge/iharder/base64/Base64$OutputStream.class  \n",
            "  inflating: FastQC/net/sourceforge/iharder/base64/Base64.class  \n",
            "   creating: FastQC/org/\n",
            "   creating: FastQC/org/apache/\n",
            "   creating: FastQC/org/apache/commons/\n",
            "   creating: FastQC/org/apache/commons/math3/\n",
            "   creating: FastQC/org/apache/commons/math3/analysis/\n",
            "   creating: FastQC/org/apache/commons/math3/analysis/solvers/\n",
            "  inflating: FastQC/org/apache/commons/math3/analysis/solvers/AbstractUnivariateSolver.class  \n",
            "  inflating: FastQC/org/apache/commons/math3/analysis/solvers/AllowedSolution.class  \n",
            "  inflating: FastQC/org/apache/commons/math3/analysis/solvers/BaseAbstractUnivariateSolver.class  \n",
            "  inflating: FastQC/org/apache/commons/math3/analysis/solvers/BaseUnivariateSolver.class  \n",
            "  inflating: FastQC/org/apache/commons/math3/analysis/solvers/BracketedUnivariateSolver.class  \n",
            "  inflating: FastQC/org/apache/commons/math3/analysis/solvers/BrentSolver.class  \n",
            "  inflating: FastQC/org/apache/commons/math3/analysis/solvers/UnivariateSolver.class  \n",
            "  inflating: FastQC/org/apache/commons/math3/analysis/solvers/UnivariateSolverUtils.class  \n",
            "  inflating: FastQC/org/apache/commons/math3/analysis/UnivariateFunction.class  \n",
            "   creating: FastQC/org/apache/commons/math3/distribution/\n",
            "  inflating: FastQC/org/apache/commons/math3/distribution/AbstractIntegerDistribution.class  \n",
            "  inflating: FastQC/org/apache/commons/math3/distribution/AbstractRealDistribution$1.class  \n",
            "  inflating: FastQC/org/apache/commons/math3/distribution/AbstractRealDistribution.class  \n",
            "  inflating: FastQC/org/apache/commons/math3/distribution/BetaDistribution.class  \n",
            "  inflating: FastQC/org/apache/commons/math3/distribution/BinomialDistribution.class  \n",
            "  inflating: FastQC/org/apache/commons/math3/distribution/CauchyDistribution.class  \n",
            "  inflating: FastQC/org/apache/commons/math3/distribution/ChiSquaredDistribution.class  \n",
            "  inflating: FastQC/org/apache/commons/math3/distribution/FDistribution.class  \n",
            "  inflating: FastQC/org/apache/commons/math3/distribution/GammaDistribution.class  \n",
            "  inflating: FastQC/org/apache/commons/math3/distribution/HypergeometricDistribution.class  \n",
            "  inflating: FastQC/org/apache/commons/math3/distribution/IntegerDistribution.class  \n",
            "  inflating: FastQC/org/apache/commons/math3/distribution/NormalDistribution.class  \n",
            "  inflating: FastQC/org/apache/commons/math3/distribution/PascalDistribution.class  \n",
            "  inflating: FastQC/org/apache/commons/math3/distribution/PoissonDistribution.class  \n",
            "  inflating: FastQC/org/apache/commons/math3/distribution/RealDistribution.class  \n",
            "  inflating: FastQC/org/apache/commons/math3/distribution/SaddlePointExpansion.class  \n",
            "  inflating: FastQC/org/apache/commons/math3/distribution/TDistribution.class  \n",
            "  inflating: FastQC/org/apache/commons/math3/distribution/WeibullDistribution.class  \n",
            "  inflating: FastQC/org/apache/commons/math3/distribution/ZipfDistribution.class  \n",
            "   creating: FastQC/org/apache/commons/math3/exception/\n",
            "  inflating: FastQC/org/apache/commons/math3/exception/ConvergenceException.class  \n",
            "  inflating: FastQC/org/apache/commons/math3/exception/DimensionMismatchException.class  \n",
            "  inflating: FastQC/org/apache/commons/math3/exception/MathArithmeticException.class  \n",
            "  inflating: FastQC/org/apache/commons/math3/exception/MathIllegalArgumentException.class  \n",
            "  inflating: FastQC/org/apache/commons/math3/exception/MathIllegalNumberException.class  \n",
            "  inflating: FastQC/org/apache/commons/math3/exception/MathIllegalStateException.class  \n",
            "  inflating: FastQC/org/apache/commons/math3/exception/MathInternalError.class  \n",
            "  inflating: FastQC/org/apache/commons/math3/exception/MaxCountExceededException.class  \n",
            "  inflating: FastQC/org/apache/commons/math3/exception/NoBracketingException.class  \n",
            "  inflating: FastQC/org/apache/commons/math3/exception/NotFiniteNumberException.class  \n",
            "  inflating: FastQC/org/apache/commons/math3/exception/NotPositiveException.class  \n",
            "  inflating: FastQC/org/apache/commons/math3/exception/NotStrictlyPositiveException.class  \n",
            "  inflating: FastQC/org/apache/commons/math3/exception/NullArgumentException.class  \n",
            "  inflating: FastQC/org/apache/commons/math3/exception/NumberIsTooLargeException.class  \n",
            "  inflating: FastQC/org/apache/commons/math3/exception/NumberIsTooSmallException.class  \n",
            "  inflating: FastQC/org/apache/commons/math3/exception/OutOfRangeException.class  \n",
            "  inflating: FastQC/org/apache/commons/math3/exception/TooManyEvaluationsException.class  \n",
            "   creating: FastQC/org/apache/commons/math3/exception/util/\n",
            "  inflating: FastQC/org/apache/commons/math3/exception/util/ArgUtils.class  \n",
            "  inflating: FastQC/org/apache/commons/math3/exception/util/ExceptionContext.class  \n",
            "  inflating: FastQC/org/apache/commons/math3/exception/util/ExceptionContextProvider.class  \n",
            "  inflating: FastQC/org/apache/commons/math3/exception/util/Localizable.class  \n",
            "  inflating: FastQC/org/apache/commons/math3/exception/util/LocalizedFormats.class  \n",
            "   creating: FastQC/org/apache/commons/math3/random/\n",
            "  inflating: FastQC/org/apache/commons/math3/random/AbstractWell.class  \n",
            "  inflating: FastQC/org/apache/commons/math3/random/BitsStreamGenerator.class  \n",
            "  inflating: FastQC/org/apache/commons/math3/random/RandomData.class  \n",
            "  inflating: FastQC/org/apache/commons/math3/random/RandomDataImpl.class  \n",
            "  inflating: FastQC/org/apache/commons/math3/random/RandomGenerator.class  \n",
            "  inflating: FastQC/org/apache/commons/math3/random/Well19937c.class  \n",
            "   creating: FastQC/org/apache/commons/math3/special/\n",
            "  inflating: FastQC/org/apache/commons/math3/special/Beta$1.class  \n",
            "  inflating: FastQC/org/apache/commons/math3/special/Beta.class  \n",
            "  inflating: FastQC/org/apache/commons/math3/special/Erf.class  \n",
            "  inflating: FastQC/org/apache/commons/math3/special/Gamma$1.class  \n",
            "  inflating: FastQC/org/apache/commons/math3/special/Gamma.class  \n",
            "   creating: FastQC/org/apache/commons/math3/util/\n",
            "  inflating: FastQC/org/apache/commons/math3/util/ArithmeticUtils.class  \n",
            "  inflating: FastQC/org/apache/commons/math3/util/ContinuedFraction.class  \n",
            "  inflating: FastQC/org/apache/commons/math3/util/DoubleArray.class  \n",
            "  inflating: FastQC/org/apache/commons/math3/util/FastMath$ExpFracTable.class  \n",
            "  inflating: FastQC/org/apache/commons/math3/util/FastMath$ExpIntTable.class  \n",
            "  inflating: FastQC/org/apache/commons/math3/util/FastMath$lnMant.class  \n",
            "  inflating: FastQC/org/apache/commons/math3/util/FastMath.class  \n",
            "  inflating: FastQC/org/apache/commons/math3/util/FastMathCalc.class  \n",
            "  inflating: FastQC/org/apache/commons/math3/util/FastMathLiteralArrays.class  \n",
            "  inflating: FastQC/org/apache/commons/math3/util/Incrementor$1.class  \n",
            "  inflating: FastQC/org/apache/commons/math3/util/Incrementor$MaxCountExceededCallback.class  \n",
            "  inflating: FastQC/org/apache/commons/math3/util/Incrementor.class  \n",
            "  inflating: FastQC/org/apache/commons/math3/util/MathUtils.class  \n",
            "  inflating: FastQC/org/apache/commons/math3/util/Precision.class  \n",
            "  inflating: FastQC/org/apache/commons/math3/util/ResizableDoubleArray.class  \n",
            "  inflating: FastQC/README.md        \n",
            "  inflating: FastQC/README.txt       \n",
            "  inflating: FastQC/RELEASE_NOTES.txt  \n",
            "  inflating: FastQC/run_fastqc.bat   \n",
            "  inflating: FastQC/sam-1.103.jar    \n",
            "   creating: FastQC/Templates/\n",
            "  inflating: FastQC/Templates/fastqc2fo.xsl  \n",
            "  inflating: FastQC/Templates/header_template.html  \n",
            "   creating: FastQC/Templates/Icons/\n",
            " extracting: FastQC/Templates/Icons/error.png  \n",
            " extracting: FastQC/Templates/Icons/fastqc_icon.png  \n",
            " extracting: FastQC/Templates/Icons/tick.png  \n",
            " extracting: FastQC/Templates/Icons/warning.png  \n",
            "   creating: FastQC/uk/\n",
            "   creating: FastQC/uk/ac/\n",
            "   creating: FastQC/uk/ac/babraham/\n",
            "   creating: FastQC/uk/ac/babraham/FastQC/\n",
            "   creating: FastQC/uk/ac/babraham/FastQC/Analysis/\n",
            "  inflating: FastQC/uk/ac/babraham/FastQC/Analysis/AnalysisListener.class  \n",
            "  inflating: FastQC/uk/ac/babraham/FastQC/Analysis/AnalysisQueue.class  \n",
            "  inflating: FastQC/uk/ac/babraham/FastQC/Analysis/AnalysisRunner.class  \n",
            "  inflating: FastQC/uk/ac/babraham/FastQC/Analysis/OfflineRunner.class  \n",
            "   creating: FastQC/uk/ac/babraham/FastQC/Dialogs/\n",
            "  inflating: FastQC/uk/ac/babraham/FastQC/Dialogs/AboutDialog$1.class  \n",
            "  inflating: FastQC/uk/ac/babraham/FastQC/Dialogs/AboutDialog.class  \n",
            "  inflating: FastQC/uk/ac/babraham/FastQC/Dialogs/FastQCTitlePanel$SmoothJLabel.class  \n",
            "  inflating: FastQC/uk/ac/babraham/FastQC/Dialogs/FastQCTitlePanel.class  \n",
            "  inflating: FastQC/uk/ac/babraham/FastQC/Dialogs/WelcomePanel.class  \n",
            "  inflating: FastQC/uk/ac/babraham/FastQC/FastQCApplication$1.class  \n",
            "  inflating: FastQC/uk/ac/babraham/FastQC/FastQCApplication.class  \n",
            "  inflating: FastQC/uk/ac/babraham/FastQC/FastQCConfig.class  \n",
            "  inflating: FastQC/uk/ac/babraham/FastQC/FastQCMenuBar.class  \n",
            "   creating: FastQC/uk/ac/babraham/FastQC/FileFilters/\n",
            "  inflating: FastQC/uk/ac/babraham/FastQC/FileFilters/BAMFileFilter.class  \n",
            "  inflating: FastQC/uk/ac/babraham/FastQC/FileFilters/CasavaFastQFileFilter.class  \n",
            "  inflating: FastQC/uk/ac/babraham/FastQC/FileFilters/FastQFileFilter.class  \n",
            "  inflating: FastQC/uk/ac/babraham/FastQC/FileFilters/GobyFileFilter.class  \n",
            "  inflating: FastQC/uk/ac/babraham/FastQC/FileFilters/MappedBAMFileFilter.class  \n",
            "  inflating: FastQC/uk/ac/babraham/FastQC/FileFilters/SequenceFileFilter.class  \n",
            "   creating: FastQC/uk/ac/babraham/FastQC/Graphs/\n",
            "  inflating: FastQC/uk/ac/babraham/FastQC/Graphs/BaseGroup.class  \n",
            "  inflating: FastQC/uk/ac/babraham/FastQC/Graphs/LineGraph.class  \n",
            "  inflating: FastQC/uk/ac/babraham/FastQC/Graphs/QualityBoxPlot.class  \n",
            "  inflating: FastQC/uk/ac/babraham/FastQC/Graphs/TileGraph.class  \n",
            "   creating: FastQC/uk/ac/babraham/FastQC/Help/\n",
            "  inflating: FastQC/uk/ac/babraham/FastQC/Help/HelpDialog.class  \n",
            "  inflating: FastQC/uk/ac/babraham/FastQC/Help/HelpIndexRoot$FileSorter.class  \n",
            "  inflating: FastQC/uk/ac/babraham/FastQC/Help/HelpIndexRoot.class  \n",
            "  inflating: FastQC/uk/ac/babraham/FastQC/Help/HelpPage.class  \n",
            "  inflating: FastQC/uk/ac/babraham/FastQC/Help/HelpPageDisplay$HelpEditor.class  \n",
            "  inflating: FastQC/uk/ac/babraham/FastQC/Help/HelpPageDisplay.class  \n",
            "  inflating: FastQC/uk/ac/babraham/FastQC/Help/HelpSearchPanel.class  \n",
            "   creating: FastQC/uk/ac/babraham/FastQC/Modules/\n",
            "  inflating: FastQC/uk/ac/babraham/FastQC/Modules/AbstractQCModule.class  \n",
            "  inflating: FastQC/uk/ac/babraham/FastQC/Modules/AdapterContent$Adapter.class  \n",
            "  inflating: FastQC/uk/ac/babraham/FastQC/Modules/AdapterContent$ResultsTable.class  \n",
            "  inflating: FastQC/uk/ac/babraham/FastQC/Modules/AdapterContent.class  \n",
            "  inflating: FastQC/uk/ac/babraham/FastQC/Modules/BasicStats$ResultsTable.class  \n",
            "  inflating: FastQC/uk/ac/babraham/FastQC/Modules/BasicStats.class  \n",
            "  inflating: FastQC/uk/ac/babraham/FastQC/Modules/DuplicationLevel.class  \n",
            "   creating: FastQC/uk/ac/babraham/FastQC/Modules/GCModel/\n",
            "  inflating: FastQC/uk/ac/babraham/FastQC/Modules/GCModel/GCModel.class  \n",
            "  inflating: FastQC/uk/ac/babraham/FastQC/Modules/GCModel/GCModelValue.class  \n",
            "  inflating: FastQC/uk/ac/babraham/FastQC/Modules/KmerContent$Kmer.class  \n",
            "  inflating: FastQC/uk/ac/babraham/FastQC/Modules/KmerContent$ResultsTable.class  \n",
            "  inflating: FastQC/uk/ac/babraham/FastQC/Modules/KmerContent.class  \n",
            "  inflating: FastQC/uk/ac/babraham/FastQC/Modules/ModuleConfig.class  \n",
            "  inflating: FastQC/uk/ac/babraham/FastQC/Modules/ModuleFactory.class  \n",
            "  inflating: FastQC/uk/ac/babraham/FastQC/Modules/NContent.class  \n",
            "  inflating: FastQC/uk/ac/babraham/FastQC/Modules/OverRepresentedSeqs$OverrepresentedSeq.class  \n",
            "  inflating: FastQC/uk/ac/babraham/FastQC/Modules/OverRepresentedSeqs$ResultsTable.class  \n",
            "  inflating: FastQC/uk/ac/babraham/FastQC/Modules/OverRepresentedSeqs.class  \n",
            "  inflating: FastQC/uk/ac/babraham/FastQC/Modules/PerBaseQualityScores.class  \n",
            "  inflating: FastQC/uk/ac/babraham/FastQC/Modules/PerBaseSequenceContent.class  \n",
            "  inflating: FastQC/uk/ac/babraham/FastQC/Modules/PerSequenceGCContent.class  \n",
            "  inflating: FastQC/uk/ac/babraham/FastQC/Modules/PerSequenceQualityScores.class  \n",
            "  inflating: FastQC/uk/ac/babraham/FastQC/Modules/PerTileQualityScores.class  \n",
            "  inflating: FastQC/uk/ac/babraham/FastQC/Modules/QCModule.class  \n",
            "  inflating: FastQC/uk/ac/babraham/FastQC/Modules/SequenceLengthDistribution.class  \n",
            "   creating: FastQC/uk/ac/babraham/FastQC/Report/\n",
            "  inflating: FastQC/uk/ac/babraham/FastQC/Report/HTMLReportArchive.class  \n",
            "  inflating: FastQC/uk/ac/babraham/FastQC/Report/stylesheet.txt  \n",
            "   creating: FastQC/uk/ac/babraham/FastQC/Resources/\n",
            " extracting: FastQC/uk/ac/babraham/FastQC/Resources/error.png  \n",
            " extracting: FastQC/uk/ac/babraham/FastQC/Resources/fastqc_icon.png  \n",
            "  inflating: FastQC/uk/ac/babraham/FastQC/Resources/fastqc_icon.svg  \n",
            " extracting: FastQC/uk/ac/babraham/FastQC/Resources/fastqc_icon_100.png  \n",
            " extracting: FastQC/uk/ac/babraham/FastQC/Resources/tick.png  \n",
            " extracting: FastQC/uk/ac/babraham/FastQC/Resources/warning.png  \n",
            "   creating: FastQC/uk/ac/babraham/FastQC/Results/\n",
            "  inflating: FastQC/uk/ac/babraham/FastQC/Results/ResultsPanel$ModuleRenderer.class  \n",
            "  inflating: FastQC/uk/ac/babraham/FastQC/Results/ResultsPanel.class  \n",
            "   creating: FastQC/uk/ac/babraham/FastQC/Sequence/\n",
            "  inflating: FastQC/uk/ac/babraham/FastQC/Sequence/BAMFile.class  \n",
            "   creating: FastQC/uk/ac/babraham/FastQC/Sequence/Contaminant/\n",
            "  inflating: FastQC/uk/ac/babraham/FastQC/Sequence/Contaminant/Contaminant.class  \n",
            "  inflating: FastQC/uk/ac/babraham/FastQC/Sequence/Contaminant/ContaminantHit.class  \n",
            "  inflating: FastQC/uk/ac/babraham/FastQC/Sequence/Contaminant/ContaminentFinder.class  \n",
            "  inflating: FastQC/uk/ac/babraham/FastQC/Sequence/Fast5File.class  \n",
            "  inflating: FastQC/uk/ac/babraham/FastQC/Sequence/FastQFile.class  \n",
            "   creating: FastQC/uk/ac/babraham/FastQC/Sequence/QualityEncoding/\n",
            "  inflating: FastQC/uk/ac/babraham/FastQC/Sequence/QualityEncoding/PhredEncoding.class  \n",
            "  inflating: FastQC/uk/ac/babraham/FastQC/Sequence/Sequence.class  \n",
            "  inflating: FastQC/uk/ac/babraham/FastQC/Sequence/SequenceFactory.class  \n",
            "  inflating: FastQC/uk/ac/babraham/FastQC/Sequence/SequenceFile.class  \n",
            "  inflating: FastQC/uk/ac/babraham/FastQC/Sequence/SequenceFileGroup.class  \n",
            "  inflating: FastQC/uk/ac/babraham/FastQC/Sequence/SequenceFormatException.class  \n",
            "   creating: FastQC/uk/ac/babraham/FastQC/Statistics/\n",
            "  inflating: FastQC/uk/ac/babraham/FastQC/Statistics/NormalDistribution.class  \n",
            "  inflating: FastQC/uk/ac/babraham/FastQC/Statistics/PearsonCorrelation.class  \n",
            "   creating: FastQC/uk/ac/babraham/FastQC/Utilities/\n",
            "  inflating: FastQC/uk/ac/babraham/FastQC/Utilities/CasavaBasename.class  \n",
            "  inflating: FastQC/uk/ac/babraham/FastQC/Utilities/HotColdColourGradient.class  \n",
            "  inflating: FastQC/uk/ac/babraham/FastQC/Utilities/ImageToBase64.class  \n",
            "  inflating: FastQC/uk/ac/babraham/FastQC/Utilities/MultiMemberGZIPInputStream.class  \n",
            "  inflating: FastQC/uk/ac/babraham/FastQC/Utilities/NameFormatException.class  \n",
            "  inflating: FastQC/uk/ac/babraham/FastQC/Utilities/NanoporeBasename.class  \n",
            "  inflating: FastQC/uk/ac/babraham/FastQC/Utilities/QualityCount.class  \n",
            "  inflating: FastQC/uk/ac/babraham/FastQC/Utilities/RGB.class  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S79LH0aXbvLx"
      },
      "source": [
        "!chmod a+x FastQC/fastqc"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PsLuZDt4b7jT",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e324218f-17dd-451f-fb44-608cc728f8da"
      },
      "source": [
        "!./FastQC/fastqc --help"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "            FastQC - A high throughput sequence QC analysis tool\n",
            "\n",
            "SYNOPSIS\n",
            "\n",
            "\tfastqc seqfile1 seqfile2 .. seqfileN\n",
            "\n",
            "    fastqc [-o output dir] [--(no)extract] [-f fastq|bam|sam] \n",
            "           [-c contaminant file] seqfile1 .. seqfileN\n",
            "\n",
            "DESCRIPTION\n",
            "\n",
            "    FastQC reads a set of sequence files and produces from each one a quality\n",
            "    control report consisting of a number of different modules, each one of \n",
            "    which will help to identify a different potential type of problem in your\n",
            "    data.\n",
            "    \n",
            "    If no files to process are specified on the command line then the program\n",
            "    will start as an interactive graphical application.  If files are provided\n",
            "    on the command line then the program will run with no user interaction\n",
            "    required.  In this mode it is suitable for inclusion into a standardised\n",
            "    analysis pipeline.\n",
            "    \n",
            "    The options for the program as as follows:\n",
            "    \n",
            "    -h --help       Print this help file and exit\n",
            "    \n",
            "    -v --version    Print the version of the program and exit\n",
            "    \n",
            "    -o --outdir     Create all output files in the specified output directory.\n",
            "                    Please note that this directory must exist as the program\n",
            "                    will not create it.  If this option is not set then the \n",
            "                    output file for each sequence file is created in the same\n",
            "                    directory as the sequence file which was processed.\n",
            "                    \n",
            "    --casava        Files come from raw casava output. Files in the same sample\n",
            "                    group (differing only by the group number) will be analysed\n",
            "                    as a set rather than individually. Sequences with the filter\n",
            "                    flag set in the header will be excluded from the analysis.\n",
            "                    Files must have the same names given to them by casava\n",
            "                    (including being gzipped and ending with .gz) otherwise they\n",
            "                    won't be grouped together correctly.\n",
            "                    \n",
            "    --nano          Files come from nanopore sequences and are in fast5 format. In\n",
            "                    this mode you can pass in directories to process and the program\n",
            "                    will take in all fast5 files within those directories and produce\n",
            "                    a single output file from the sequences found in all files.                    \n",
            "                    \n",
            "    --nofilter      If running with --casava then don't remove read flagged by\n",
            "                    casava as poor quality when performing the QC analysis.\n",
            "                   \n",
            "    --extract       If set then the zipped output file will be uncompressed in\n",
            "                    the same directory after it has been created.  By default\n",
            "                    this option will be set if fastqc is run in non-interactive\n",
            "                    mode.\n",
            "                    \n",
            "    -j --java       Provides the full path to the java binary you want to use to\n",
            "                    launch fastqc. If not supplied then java is assumed to be in\n",
            "                    your path.\n",
            "                   \n",
            "    --noextract     Do not uncompress the output file after creating it.  You\n",
            "                    should set this option if you do not wish to uncompress\n",
            "                    the output when running in non-interactive mode.\n",
            "                    \n",
            "    --nogroup       Disable grouping of bases for reads >50bp. All reports will\n",
            "                    show data for every base in the read.  WARNING: Using this\n",
            "                    option will cause fastqc to crash and burn if you use it on\n",
            "                    really long reads, and your plots may end up a ridiculous size.\n",
            "                    You have been warned!\n",
            "                    \n",
            "    --min_length    Sets an artificial lower limit on the length of the sequence\n",
            "                    to be shown in the report.  As long as you set this to a value\n",
            "                    greater or equal to your longest read length then this will be\n",
            "                    the sequence length used to create your read groups.  This can\n",
            "                    be useful for making directly comaparable statistics from \n",
            "                    datasets with somewhat variable read lengths.\n",
            "                    \n",
            "    -f --format     Bypasses the normal sequence file format detection and\n",
            "                    forces the program to use the specified format.  Valid\n",
            "                    formats are bam,sam,bam_mapped,sam_mapped and fastq\n",
            "                    \n",
            "    -t --threads    Specifies the number of files which can be processed\n",
            "                    simultaneously.  Each thread will be allocated 250MB of\n",
            "                    memory so you shouldn't run more threads than your\n",
            "                    available memory will cope with, and not more than\n",
            "                    6 threads on a 32 bit machine\n",
            "                  \n",
            "    -c              Specifies a non-default file which contains the list of\n",
            "    --contaminants  contaminants to screen overrepresented sequences against.\n",
            "                    The file must contain sets of named contaminants in the\n",
            "                    form name[tab]sequence.  Lines prefixed with a hash will\n",
            "                    be ignored.\n",
            "\n",
            "    -a              Specifies a non-default file which contains the list of\n",
            "    --adapters      adapter sequences which will be explicity searched against\n",
            "                    the library. The file must contain sets of named adapters\n",
            "                    in the form name[tab]sequence.  Lines prefixed with a hash\n",
            "                    will be ignored.\n",
            "                    \n",
            "    -l              Specifies a non-default file which contains a set of criteria\n",
            "    --limits        which will be used to determine the warn/error limits for the\n",
            "                    various modules.  This file can also be used to selectively \n",
            "                    remove some modules from the output all together.  The format\n",
            "                    needs to mirror the default limits.txt file found in the\n",
            "                    Configuration folder.\n",
            "                    \n",
            "   -k --kmers       Specifies the length of Kmer to look for in the Kmer content\n",
            "                    module. Specified Kmer length must be between 2 and 10. Default\n",
            "                    length is 7 if not specified.\n",
            "                    \n",
            "   -q --quiet       Supress all progress messages on stdout and only report errors.\n",
            "   \n",
            "   -d --dir         Selects a directory to be used for temporary files written when\n",
            "                    generating report images. Defaults to system temp directory if\n",
            "                    not specified.\n",
            "                    \n",
            "BUGS\n",
            "\n",
            "    Any bugs in fastqc should be reported either to simon.andrews@babraham.ac.uk\n",
            "    or in www.bioinformatics.babraham.ac.uk/bugzilla/\n",
            "                   \n",
            "    \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3dqWpZZ_0_V-"
      },
      "source": [
        "## Установка HTSeq-count"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1_yqggdMhMfj",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1ed0a9b8-64e0-4dec-ee1f-2b8b42b54486"
      },
      "source": [
        "!pip install HTSeq"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting HTSeq\n",
            "  Downloading HTSeq-1.99.2-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (1.5 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.5 MB 5.4 MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from HTSeq) (1.19.5)\n",
            "Collecting pysam\n",
            "  Downloading pysam-0.18.0-cp37-cp37m-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (14.9 MB)\n",
            "\u001b[K     |████████████████████████████████| 14.9 MB 16.0 MB/s \n",
            "\u001b[?25hInstalling collected packages: pysam, HTSeq\n",
            "Successfully installed HTSeq-1.99.2 pysam-0.18.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L7W0Ep2nhT_d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "aaa96e76-c838-47d7-af7b-fad721308abb"
      },
      "source": [
        "!htseq-count --version"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/bin/htseq-count\", line 3, in <module>\n",
            "    import HTSeq.scripts.count\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/HTSeq/__init__.py\", line 13, in <module>\n",
            "    from HTSeq._HTSeq import *\n",
            "  File \"src/HTSeq/_HTSeq.pyx\", line 1, in init HTSeq._HTSeq\n",
            "ValueError: numpy.ndarray size changed, may indicate binary incompatibility. Expected 88 from C header, got 80 from PyObject\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mhpeqACAXfkA",
        "outputId": "9c81ed5f-da49-47c2-d5de-212a02ad752a"
      },
      "source": [
        "!pip install multiqc"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting multiqc\n",
            "  Downloading multiqc-1.11-py3-none-any.whl (1.2 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.2 MB 5.4 MB/s \n",
            "\u001b[?25hRequirement already satisfied: matplotlib>=2.1.1 in /usr/local/lib/python3.7/dist-packages (from multiqc) (3.2.2)\n",
            "Collecting simplejson\n",
            "  Downloading simplejson-3.17.6-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (130 kB)\n",
            "\u001b[K     |████████████████████████████████| 130 kB 47.3 MB/s \n",
            "\u001b[?25hCollecting lzstring\n",
            "  Downloading lzstring-1.0.4.tar.gz (4.3 kB)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from multiqc) (1.19.5)\n",
            "Collecting spectra>=0.0.10\n",
            "  Downloading spectra-0.0.11.tar.gz (18 kB)\n",
            "Requirement already satisfied: jinja2>=2.9 in /usr/local/lib/python3.7/dist-packages (from multiqc) (2.11.3)\n",
            "Collecting coloredlogs\n",
            "  Downloading coloredlogs-15.0.1-py2.py3-none-any.whl (46 kB)\n",
            "\u001b[K     |████████████████████████████████| 46 kB 3.3 MB/s \n",
            "\u001b[?25hRequirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from multiqc) (7.1.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from multiqc) (2.23.0)\n",
            "Requirement already satisfied: future>0.14.0 in /usr/local/lib/python3.7/dist-packages (from multiqc) (0.16.0)\n",
            "Requirement already satisfied: networkx>=2.5.1 in /usr/local/lib/python3.7/dist-packages (from multiqc) (2.6.3)\n",
            "Collecting rich>=10\n",
            "  Downloading rich-10.15.1-py3-none-any.whl (214 kB)\n",
            "\u001b[K     |████████████████████████████████| 214 kB 50.9 MB/s \n",
            "\u001b[?25hRequirement already satisfied: markdown in /usr/local/lib/python3.7/dist-packages (from multiqc) (3.3.6)\n",
            "Collecting pyyaml>=4\n",
            "  Downloading PyYAML-6.0-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (596 kB)\n",
            "\u001b[K     |████████████████████████████████| 596 kB 34.1 MB/s \n",
            "\u001b[?25hRequirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.7/dist-packages (from jinja2>=2.9->multiqc) (2.0.1)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib>=2.1.1->multiqc) (2.8.2)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib>=2.1.1->multiqc) (3.0.6)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib>=2.1.1->multiqc) (0.11.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib>=2.1.1->multiqc) (1.3.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.1->matplotlib>=2.1.1->multiqc) (1.15.0)\n",
            "Requirement already satisfied: typing-extensions<5.0,>=3.7.4 in /usr/local/lib/python3.7/dist-packages (from rich>=10->multiqc) (3.10.0.2)\n",
            "Collecting colorama<0.5.0,>=0.4.0\n",
            "  Downloading colorama-0.4.4-py2.py3-none-any.whl (16 kB)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.6.0 in /usr/local/lib/python3.7/dist-packages (from rich>=10->multiqc) (2.6.1)\n",
            "Collecting commonmark<0.10.0,>=0.9.0\n",
            "  Downloading commonmark-0.9.1-py2.py3-none-any.whl (51 kB)\n",
            "\u001b[K     |████████████████████████████████| 51 kB 4.8 MB/s \n",
            "\u001b[?25hCollecting colormath>=3.0.0\n",
            "  Downloading colormath-3.0.0.tar.gz (39 kB)\n",
            "Collecting humanfriendly>=9.1\n",
            "  Downloading humanfriendly-10.0-py2.py3-none-any.whl (86 kB)\n",
            "\u001b[K     |████████████████████████████████| 86 kB 5.8 MB/s \n",
            "\u001b[?25hRequirement already satisfied: importlib-metadata>=4.4 in /usr/local/lib/python3.7/dist-packages (from markdown->multiqc) (4.8.2)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=4.4->markdown->multiqc) (3.6.0)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->multiqc) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->multiqc) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->multiqc) (2021.10.8)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->multiqc) (2.10)\n",
            "Building wheels for collected packages: spectra, colormath, lzstring\n",
            "  Building wheel for spectra (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for spectra: filename=spectra-0.0.11-py3-none-any.whl size=17488 sha256=a435613fb2288cf3d7872daefdb6386e07c7937b3b26772848b0760d3af96669\n",
            "  Stored in directory: /root/.cache/pip/wheels/e3/c8/a4/5a566fafff827fcb5741589e42002686bb29990fbc7b262b5e\n",
            "  Building wheel for colormath (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for colormath: filename=colormath-3.0.0-py3-none-any.whl size=39408 sha256=77c5f5f0a116eb02323018d205d7297035f713ee7d4e9a00827426f29965f212\n",
            "  Stored in directory: /root/.cache/pip/wheels/1a/d7/a7/458a4632ccc8bfe436f5e9db9fef1aa84e5d243a1b4b4c7b59\n",
            "  Building wheel for lzstring (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for lzstring: filename=lzstring-1.0.4-py2.py3-none-any.whl size=4591 sha256=20021eccfc4cea0f2b89cbaddabc6aad5aa3a9709ba708bba96455f859a08a08\n",
            "  Stored in directory: /root/.cache/pip/wheels/f1/e0/9f/2d1e57842b9e3a9f030519f6ea5e55a21ba7d4f5bcbb4ef578\n",
            "Successfully built spectra colormath lzstring\n",
            "Installing collected packages: humanfriendly, commonmark, colormath, colorama, spectra, simplejson, rich, pyyaml, lzstring, coloredlogs, multiqc\n",
            "  Attempting uninstall: pyyaml\n",
            "    Found existing installation: PyYAML 3.13\n",
            "    Uninstalling PyYAML-3.13:\n",
            "      Successfully uninstalled PyYAML-3.13\n",
            "Successfully installed colorama-0.4.4 coloredlogs-15.0.1 colormath-3.0.0 commonmark-0.9.1 humanfriendly-10.0 lzstring-1.0.4 multiqc-1.11 pyyaml-6.0 rich-10.15.1 simplejson-3.17.6 spectra-0.0.11\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I6MhDf5N2tQ3"
      },
      "source": [
        "## Скачиваем RNA-seq данные"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LicIlxo028wE"
      },
      "source": [
        "* Перепрограммированные образцы: \tSRR3414629, SRR3414630, SRR3414631\n",
        "* Контрольные образцы:\t\tSRR3414635, SRR3414636, SRR3414637\n",
        "\n",
        "**Один образец скачивается 5-10 мин!!**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c7-OCZli2z38",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ca9bb774-4ab8-4b5b-f11c-64d7fced4943"
      },
      "source": [
        "!time  fastq-dump  --split-files  SRR3414629\n",
        "!./FastQC/fastqc  /content/SRR3414629_1.fastq\n",
        "\n",
        "!time  fastq-dump  --split-files  SRR3414630\n",
        "!./FastQC/fastqc  /content/SRR3414630_1.fastq\n",
        "\n",
        "!time  fastq-dump  --split-files  SRR3414631\n",
        "!./FastQC/fastqc  /content/SRR3414631_1.fastq\n",
        "\n",
        "!time  fastq-dump  --split-files  SRR3414635\n",
        "!./FastQC/fastqc  /content/SRR3414635_1.fastq\n",
        "\n",
        "!time  fastq-dump  --split-files  SRR3414636\n",
        "!./FastQC/fastqc  /content/SRR3414636_1.fastq\n",
        "\n",
        "!time  fastq-dump  --split-files  SRR3414637\n",
        "!./FastQC/fastqc  /content/SRR3414637_1.fastq\n",
        "\n",
        "!multiqc . --filename concatenated_report.html"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Read 21106089 spots for SRR3414629\n",
            "Written 21106089 spots for SRR3414629\n",
            "\n",
            "real\t6m12.770s\n",
            "user\t2m53.365s\n",
            "sys\t0m8.317s\n",
            "Started analysis of SRR3414629_1.fastq\n",
            "Approx 5% complete for SRR3414629_1.fastq\n",
            "Approx 10% complete for SRR3414629_1.fastq\n",
            "Approx 15% complete for SRR3414629_1.fastq\n",
            "Approx 20% complete for SRR3414629_1.fastq\n",
            "Approx 25% complete for SRR3414629_1.fastq\n",
            "Approx 30% complete for SRR3414629_1.fastq\n",
            "Approx 35% complete for SRR3414629_1.fastq\n",
            "Approx 40% complete for SRR3414629_1.fastq\n",
            "Approx 45% complete for SRR3414629_1.fastq\n",
            "Approx 50% complete for SRR3414629_1.fastq\n",
            "Approx 55% complete for SRR3414629_1.fastq\n",
            "Approx 60% complete for SRR3414629_1.fastq\n",
            "Approx 65% complete for SRR3414629_1.fastq\n",
            "Approx 70% complete for SRR3414629_1.fastq\n",
            "Approx 75% complete for SRR3414629_1.fastq\n",
            "Approx 80% complete for SRR3414629_1.fastq\n",
            "Approx 85% complete for SRR3414629_1.fastq\n",
            "Approx 90% complete for SRR3414629_1.fastq\n",
            "Approx 95% complete for SRR3414629_1.fastq\n",
            "Analysis complete for SRR3414629_1.fastq\n",
            "Read 15244711 spots for SRR3414630\n",
            "Written 15244711 spots for SRR3414630\n",
            "\n",
            "real\t4m29.537s\n",
            "user\t2m5.735s\n",
            "sys\t0m5.885s\n",
            "Started analysis of SRR3414630_1.fastq\n",
            "Approx 5% complete for SRR3414630_1.fastq\n",
            "Approx 10% complete for SRR3414630_1.fastq\n",
            "Approx 15% complete for SRR3414630_1.fastq\n",
            "Approx 20% complete for SRR3414630_1.fastq\n",
            "Approx 25% complete for SRR3414630_1.fastq\n",
            "Approx 30% complete for SRR3414630_1.fastq\n",
            "Approx 35% complete for SRR3414630_1.fastq\n",
            "Approx 40% complete for SRR3414630_1.fastq\n",
            "Approx 45% complete for SRR3414630_1.fastq\n",
            "Approx 50% complete for SRR3414630_1.fastq\n",
            "Approx 55% complete for SRR3414630_1.fastq\n",
            "Approx 60% complete for SRR3414630_1.fastq\n",
            "Approx 65% complete for SRR3414630_1.fastq\n",
            "Approx 70% complete for SRR3414630_1.fastq\n",
            "Approx 75% complete for SRR3414630_1.fastq\n",
            "Approx 80% complete for SRR3414630_1.fastq\n",
            "Approx 85% complete for SRR3414630_1.fastq\n",
            "Approx 90% complete for SRR3414630_1.fastq\n",
            "Approx 95% complete for SRR3414630_1.fastq\n",
            "Analysis complete for SRR3414630_1.fastq\n",
            "Read 24244069 spots for SRR3414631\n",
            "Written 24244069 spots for SRR3414631\n",
            "\n",
            "real\t7m11.834s\n",
            "user\t3m20.524s\n",
            "sys\t0m9.296s\n",
            "Started analysis of SRR3414631_1.fastq\n",
            "Approx 5% complete for SRR3414631_1.fastq\n",
            "Approx 10% complete for SRR3414631_1.fastq\n",
            "Approx 15% complete for SRR3414631_1.fastq\n",
            "Approx 20% complete for SRR3414631_1.fastq\n",
            "Approx 25% complete for SRR3414631_1.fastq\n",
            "Approx 30% complete for SRR3414631_1.fastq\n",
            "Approx 35% complete for SRR3414631_1.fastq\n",
            "Approx 40% complete for SRR3414631_1.fastq\n",
            "Approx 45% complete for SRR3414631_1.fastq\n",
            "Approx 50% complete for SRR3414631_1.fastq\n",
            "Approx 55% complete for SRR3414631_1.fastq\n",
            "Approx 60% complete for SRR3414631_1.fastq\n",
            "Approx 65% complete for SRR3414631_1.fastq\n",
            "Approx 70% complete for SRR3414631_1.fastq\n",
            "Approx 75% complete for SRR3414631_1.fastq\n",
            "Approx 80% complete for SRR3414631_1.fastq\n",
            "Approx 85% complete for SRR3414631_1.fastq\n",
            "Approx 90% complete for SRR3414631_1.fastq\n",
            "Approx 95% complete for SRR3414631_1.fastq\n",
            "Analysis complete for SRR3414631_1.fastq\n",
            "Read 20956475 spots for SRR3414635\n",
            "Written 20956475 spots for SRR3414635\n",
            "\n",
            "real\t6m12.861s\n",
            "user\t2m53.297s\n",
            "sys\t0m8.732s\n",
            "Started analysis of SRR3414635_1.fastq\n",
            "Approx 5% complete for SRR3414635_1.fastq\n",
            "Approx 10% complete for SRR3414635_1.fastq\n",
            "Approx 15% complete for SRR3414635_1.fastq\n",
            "Approx 20% complete for SRR3414635_1.fastq\n",
            "Approx 25% complete for SRR3414635_1.fastq\n",
            "Approx 30% complete for SRR3414635_1.fastq\n",
            "Approx 35% complete for SRR3414635_1.fastq\n",
            "Approx 40% complete for SRR3414635_1.fastq\n",
            "Approx 45% complete for SRR3414635_1.fastq\n",
            "Approx 50% complete for SRR3414635_1.fastq\n",
            "Approx 55% complete for SRR3414635_1.fastq\n",
            "Approx 60% complete for SRR3414635_1.fastq\n",
            "Approx 65% complete for SRR3414635_1.fastq\n",
            "Approx 70% complete for SRR3414635_1.fastq\n",
            "Approx 75% complete for SRR3414635_1.fastq\n",
            "Approx 80% complete for SRR3414635_1.fastq\n",
            "Approx 85% complete for SRR3414635_1.fastq\n",
            "Approx 90% complete for SRR3414635_1.fastq\n",
            "Approx 95% complete for SRR3414635_1.fastq\n",
            "Analysis complete for SRR3414635_1.fastq\n",
            "Read 20307147 spots for SRR3414636\n",
            "Written 20307147 spots for SRR3414636\n",
            "\n",
            "real\t5m58.732s\n",
            "user\t2m46.936s\n",
            "sys\t0m7.481s\n",
            "Started analysis of SRR3414636_1.fastq\n",
            "Approx 5% complete for SRR3414636_1.fastq\n",
            "Approx 10% complete for SRR3414636_1.fastq\n",
            "Approx 15% complete for SRR3414636_1.fastq\n",
            "Approx 20% complete for SRR3414636_1.fastq\n",
            "Approx 25% complete for SRR3414636_1.fastq\n",
            "Approx 30% complete for SRR3414636_1.fastq\n",
            "Approx 35% complete for SRR3414636_1.fastq\n",
            "Approx 40% complete for SRR3414636_1.fastq\n",
            "Approx 45% complete for SRR3414636_1.fastq\n",
            "Approx 50% complete for SRR3414636_1.fastq\n",
            "Approx 55% complete for SRR3414636_1.fastq\n",
            "Approx 60% complete for SRR3414636_1.fastq\n",
            "Approx 65% complete for SRR3414636_1.fastq\n",
            "Approx 70% complete for SRR3414636_1.fastq\n",
            "Approx 75% complete for SRR3414636_1.fastq\n",
            "Approx 80% complete for SRR3414636_1.fastq\n",
            "Approx 85% complete for SRR3414636_1.fastq\n",
            "Approx 90% complete for SRR3414636_1.fastq\n",
            "Approx 95% complete for SRR3414636_1.fastq\n",
            "Analysis complete for SRR3414636_1.fastq\n",
            "Read 20385570 spots for SRR3414637\n",
            "Written 20385570 spots for SRR3414637\n",
            "\n",
            "real\t6m1.507s\n",
            "user\t2m48.161s\n",
            "sys\t0m8.091s\n",
            "Started analysis of SRR3414637_1.fastq\n",
            "Approx 5% complete for SRR3414637_1.fastq\n",
            "Approx 10% complete for SRR3414637_1.fastq\n",
            "Approx 15% complete for SRR3414637_1.fastq\n",
            "Approx 20% complete for SRR3414637_1.fastq\n",
            "Approx 25% complete for SRR3414637_1.fastq\n",
            "Approx 30% complete for SRR3414637_1.fastq\n",
            "Approx 35% complete for SRR3414637_1.fastq\n",
            "Approx 40% complete for SRR3414637_1.fastq\n",
            "Approx 45% complete for SRR3414637_1.fastq\n",
            "Approx 50% complete for SRR3414637_1.fastq\n",
            "Approx 55% complete for SRR3414637_1.fastq\n",
            "Approx 60% complete for SRR3414637_1.fastq\n",
            "Approx 65% complete for SRR3414637_1.fastq\n",
            "Approx 70% complete for SRR3414637_1.fastq\n",
            "Approx 75% complete for SRR3414637_1.fastq\n",
            "Approx 80% complete for SRR3414637_1.fastq\n",
            "Approx 85% complete for SRR3414637_1.fastq\n",
            "Approx 90% complete for SRR3414637_1.fastq\n",
            "Approx 95% complete for SRR3414637_1.fastq\n",
            "Analysis complete for SRR3414637_1.fastq\n",
            "\n",
            "  \u001b[34m/\u001b[0m\u001b[32m/\u001b[0m\u001b[31m/\u001b[0m \u001b]8;id=907670;https://multiqc.info\u001b\\\u001b[1mMultiQC\u001b[0m\u001b]8;;\u001b\\ 🔍 \u001b[2m| v1.11\u001b[0m\n",
            "\n",
            "\u001b[34m|           multiqc\u001b[0m | Search path : /content\n",
            "\u001b[2K\u001b[34m|\u001b[0m         \u001b[34msearching\u001b[0m | \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[35m100%\u001b[0m \u001b[32m292/292\u001b[0m  \n",
            "\u001b[?25h\u001b[34m|            fastqc\u001b[0m | Found 6 reports\n",
            "\u001b[34m|           multiqc\u001b[0m | Compressing plot data\n",
            "\u001b[34m|           multiqc\u001b[0m | Report      : concatenated_report.html\n",
            "\u001b[34m|           multiqc\u001b[0m | Data        : concatenated_report_data\n",
            "\u001b[34m|           multiqc\u001b[0m | MultiQC complete\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HAn1rivS0BME"
      },
      "source": [
        "## Скачиваем геном мыши mm10 (проиндексированный для HISAT2)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wWfSQMGZ03Ch",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a6d8133a-984f-4b85-e608-7588776b970c"
      },
      "source": [
        "!wget https://genome-idx.s3.amazonaws.com/hisat/mm10_genome.tar.gz"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2021-12-01 07:32:51--  https://genome-idx.s3.amazonaws.com/hisat/mm10_genome.tar.gz\n",
            "Resolving genome-idx.s3.amazonaws.com (genome-idx.s3.amazonaws.com)... 52.217.133.161\n",
            "Connecting to genome-idx.s3.amazonaws.com (genome-idx.s3.amazonaws.com)|52.217.133.161|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 3804366597 (3.5G) [binary/octet-stream]\n",
            "Saving to: ‘mm10_genome.tar.gz’\n",
            "\n",
            "mm10_genome.tar.gz  100%[===================>]   3.54G  24.9MB/s    in 2m 12s  \n",
            "\n",
            "2021-12-01 07:35:03 (27.5 MB/s) - ‘mm10_genome.tar.gz’ saved [3804366597/3804366597]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9IKaXKp7eLjq",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5b15235b-b7af-497d-c6d6-bded7f2df507"
      },
      "source": [
        "!tar -xzvf mm10_genome.tar.gz"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "mm10/\n",
            "mm10/genome.8.ht2\n",
            "mm10/genome.5.ht2\n",
            "mm10/make_mm10.sh\n",
            "mm10/genome.7.ht2\n",
            "mm10/genome.6.ht2\n",
            "mm10/genome.4.ht2\n",
            "mm10/genome.3.ht2\n",
            "mm10/genome.1.ht2\n",
            "mm10/genome.2.ht2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sGULD5P70tvT"
      },
      "source": [
        "## Скачиваем аннотацию генов GENCODE для генома мыши mm10"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P8SxMZMC3Aw-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f80335d4-4243-40d3-907c-0692a2b52d94"
      },
      "source": [
        "!wget http://ftp.ebi.ac.uk/pub/databases/gencode/Gencode_mouse/release_M25/gencode.vM25.annotation.gtf.gz"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2021-12-01 07:35:52--  http://ftp.ebi.ac.uk/pub/databases/gencode/Gencode_mouse/release_M25/gencode.vM25.annotation.gtf.gz\n",
            "Resolving ftp.ebi.ac.uk (ftp.ebi.ac.uk)... 193.62.197.74\n",
            "Connecting to ftp.ebi.ac.uk (ftp.ebi.ac.uk)|193.62.197.74|:80... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 28542432 (27M) [application/octet-stream]\n",
            "Saving to: ‘gencode.vM25.annotation.gtf.gz’\n",
            "\n",
            "gencode.vM25.annota 100%[===================>]  27.22M   647KB/s    in 46s     \n",
            "\n",
            "2021-12-01 07:36:38 (610 KB/s) - ‘gencode.vM25.annotation.gtf.gz’ saved [28542432/28542432]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K9RerBtX8iFF"
      },
      "source": [
        "!gzip -d gencode.vM25.annotation.gtf.gz"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zzucvMQkzzs9"
      },
      "source": [
        "# Выравнивание чтений"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 153
        },
        "id": "CFQkvQlTVli7",
        "outputId": "0366d5a7-cb2d-4420-8516-cf40ffefcea7"
      },
      "source": [
        "from google.colab import files\n",
        "\n",
        "!zip -r /content/concatenated_report_data.zip /content/concatenated_report_data\n",
        "files.download('concatenated_report_data.zip')\n",
        "files.download('concatenated_report.html')"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  adding: content/concatenated_report_data/ (stored 0%)\n",
            "  adding: content/concatenated_report_data/multiqc.log (deflated 95%)\n",
            "  adding: content/concatenated_report_data/multiqc_general_stats.txt (deflated 63%)\n",
            "  adding: content/concatenated_report_data/multiqc_sources.txt (deflated 71%)\n",
            "  adding: content/concatenated_report_data/multiqc_data.json (deflated 92%)\n",
            "  adding: content/concatenated_report_data/multiqc_fastqc.txt (deflated 70%)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "download(\"download_05747f6f-310d-42af-bf2d-20535b64a122\", \"concatenated_report_data.zip\", 39344)"
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "download(\"download_2ffdd883-fc06-469b-87c3-7d93637688d6\", \"concatenated_report.html\", 1224057)"
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bH70xoP87343"
      },
      "source": [
        "**Ниже приведены примеры запуска только для одного файла. Вам следует сделать это для всех 6-ти файлов.**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TRBfl7NL3xgN"
      },
      "source": [
        "* Для каждого образца запускаем FastQC. Скачиваем полученные html файлы и проверяем есть ли проблемы с файлами. Можно также установить multiqc и получить объединенный .html файл. Полученные результаты приводим в отчете на Github-е.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b23N89JW4Eeg"
      },
      "source": [
        "* Запускаем HISAT2 и картируем все чтения на геном мыши.\n",
        "* **Для одного образца программа работает 10-15 мин**\n",
        "* Общее кол-во чтений, и кол-во, которое удалось успешно откартировать (уникально и не уникально), указано в файле SRR3414636.hisat. Приводим эту информацию в отчете на Github"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "us6WSL8Ge6U_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c1dcc7ea-27f3-44f9-b622-541733c217c8"
      },
      "source": [
        "!time hisat2 -p 3 -x mm10/genome -U SRR3414629_1.fastq -S SRR3414629_1.sam  2>  SRR3414629.hisat\n",
        "!cat SRR3414629.hisat\n",
        "!grep -P '^@|NH:i:1$' SRR3414629_1.sam > SRR3414629.uniq.sam\n",
        "!rm -v SRR3414629_1.sam\n",
        "!grep -v '^@' SRR3414629.uniq.sam | wc -l"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "real\t10m35.478s\n",
            "user\t19m5.407s\n",
            "sys\t1m12.457s\n",
            "21106089 reads; of these:\n",
            "  21106089 (100.00%) were unpaired; of these:\n",
            "    595976 (2.82%) aligned 0 times\n",
            "    18375888 (87.06%) aligned exactly 1 time\n",
            "    2134225 (10.11%) aligned >1 times\n",
            "97.18% overall alignment rate\n",
            "removed 'SRR3414629_1.sam'\n",
            "18375888\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mjIw2INNqSXt"
      },
      "source": [
        "!rm SRR3414629.hisat\n",
        "!rm SRR3414629_1.fastq"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "87_JFD0cmEP7",
        "outputId": "340b388b-f1f5-4b8a-923d-84fa7fbf2a6f"
      },
      "source": [
        "!time hisat2 -p 3 -x mm10/genome -U SRR3414630_1.fastq -S SRR3414630_1.sam  2>  SRR3414630.hisat\n",
        "!cat SRR3414630.hisat\n",
        "!grep -P '^@|NH:i:1$' SRR3414630_1.sam > SRR3414630.uniq.sam\n",
        "!rm -v SRR3414630_1.sam\n",
        "!grep -v '^@' SRR3414630.uniq.sam | wc -l"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "real\t8m43.625s\n",
            "user\t13m58.648s\n",
            "sys\t0m52.915s\n",
            "15244711 reads; of these:\n",
            "  15244711 (100.00%) were unpaired; of these:\n",
            "    412031 (2.70%) aligned 0 times\n",
            "    13186139 (86.50%) aligned exactly 1 time\n",
            "    1646541 (10.80%) aligned >1 times\n",
            "97.30% overall alignment rate\n",
            "removed 'SRR3414630_1.sam'\n",
            "13186139\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wihVQDh-qtLR"
      },
      "source": [
        "!rm SRR3414630.hisat\n",
        "!rm SRR3414630_1.fastq"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jT7k6P2MmE-R",
        "outputId": "948825b0-3ce1-4b9d-ae78-7328e779a377"
      },
      "source": [
        "!time hisat2 -p 3 -x mm10/genome -U SRR3414631_1.fastq -S SRR3414631_1.sam  2>  SRR3414631.hisat\n",
        "!cat SRR3414631.hisat\n",
        "!grep -P '^@|NH:i:1$' SRR3414631_1.sam > SRR3414631.uniq.sam\n",
        "!rm -v SRR3414631_1.sam\n",
        "!grep -v '^@' SRR3414631.uniq.sam | wc -l"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "real\t13m58.498s\n",
            "user\t23m37.483s\n",
            "sys\t1m21.142s\n",
            "24244069 reads; of these:\n",
            "  24244069 (100.00%) were unpaired; of these:\n",
            "    696383 (2.87%) aligned 0 times\n",
            "    20928945 (86.33%) aligned exactly 1 time\n",
            "    2618741 (10.80%) aligned >1 times\n",
            "97.13% overall alignment rate\n",
            "removed 'SRR3414631_1.sam'\n",
            "20928945\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wTcjX55mqv4U"
      },
      "source": [
        "!rm SRR3414631.hisat\n",
        "!rm SRR3414631_1.fastq"
      ],
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XM5NKd5cmFm-",
        "outputId": "bd5acc9a-9e71-49ba-bda8-75c3935bc509"
      },
      "source": [
        "!time hisat2 -p 3 -x mm10/genome -U SRR3414635_1.fastq -S SRR3414635_1.sam  2>  SRR3414635.hisat\n",
        "!cat SRR3414635.hisat\n",
        "!grep -P '^@|NH:i:1$' SRR3414635_1.sam > SRR3414635.uniq.sam\n",
        "!rm -v SRR3414635_1.sam\n",
        "!grep -v '^@' SRR3414635.uniq.sam | wc -l"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "real\t11m41.606s\n",
            "user\t19m21.150s\n",
            "sys\t1m7.932s\n",
            "20956475 reads; of these:\n",
            "  20956475 (100.00%) were unpaired; of these:\n",
            "    560610 (2.68%) aligned 0 times\n",
            "    18428317 (87.94%) aligned exactly 1 time\n",
            "    1967548 (9.39%) aligned >1 times\n",
            "97.32% overall alignment rate\n",
            "removed 'SRR3414635_1.sam'\n",
            "18428317\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5Lvho_17qxne"
      },
      "source": [
        "!rm SRR3414635.hisat\n",
        "!rm SRR3414635_1.fastq"
      ],
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L3WKl9ZRmHfA",
        "outputId": "72854e22-4719-4ada-b8c1-7aca8e0cfbbf"
      },
      "source": [
        "!time hisat2 -p 3 -x mm10/genome -U SRR3414636_1.fastq -S SRR3414636_1.sam  2>  SRR3414636.hisat\n",
        "!cat SRR3414636.hisat\n",
        "!grep -P '^@|NH:i:1$' SRR3414636_1.sam > SRR3414636.uniq.sam\n",
        "!rm -v SRR3414636_1.sam\n",
        "!grep -v '^@' SRR3414636.uniq.sam | wc -l"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "real\t11m15.983s\n",
            "user\t18m32.243s\n",
            "sys\t1m6.227s\n",
            "20307147 reads; of these:\n",
            "  20307147 (100.00%) were unpaired; of these:\n",
            "    550088 (2.71%) aligned 0 times\n",
            "    17825380 (87.78%) aligned exactly 1 time\n",
            "    1931679 (9.51%) aligned >1 times\n",
            "97.29% overall alignment rate\n",
            "removed 'SRR3414636_1.sam'\n",
            "17825380\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zsTMukO8qzu2"
      },
      "source": [
        "!rm SRR3414636.hisat\n",
        "!rm SRR3414636_1.fastq"
      ],
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K8_lToKfncLk",
        "outputId": "5ccb7786-2b80-4aab-d1c6-aca6028679aa"
      },
      "source": [
        "!time hisat2 -p 3 -x mm10/genome -U SRR3414637_1.fastq -S SRR3414637_1.sam  2>  SRR3414637.hisat\n",
        "!cat SRR3414637.hisat\n",
        "!grep -P '^@|NH:i:1$' SRR3414637_1.sam > SRR3414637.uniq.sam\n",
        "!rm -v SRR3414637_1.sam\n",
        "!grep -v '^@' SRR3414637.uniq.sam | wc -l"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "real\t11m18.855s\n",
            "user\t19m8.870s\n",
            "sys\t1m9.569s\n",
            "20385570 reads; of these:\n",
            "  20385570 (100.00%) were unpaired; of these:\n",
            "    538279 (2.64%) aligned 0 times\n",
            "    17844858 (87.54%) aligned exactly 1 time\n",
            "    2002433 (9.82%) aligned >1 times\n",
            "97.36% overall alignment rate\n",
            "removed 'SRR3414637_1.sam'\n",
            "17844858\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ea1KvDP5q1rA"
      },
      "source": [
        "!rm SRR3414637.hisat\n",
        "!rm SRR3414637_1.fastq"
      ],
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_JqUV4J_8a8h"
      },
      "source": [
        "* С помощью программы `HTSeq` Подсчитываем количество чтений, попавших на каждый ген (**для одного образца программа работает 15-20 мин**):\n",
        "* Аннтоация генома мыши в формате .gtf находится в файле `gencode.vM25.annotation.gtf`\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "6w4jFkHGU6NP",
        "outputId": "07973bf6-b880-46e4-b072-8f94a3976005"
      },
      "source": [
        "!time htseq-count --format=sam --stranded=no SRR3414629.uniq.sam  gencode.vM25.annotation.gtf > SRR3414629.counts\n",
        "!time htseq-count --format=sam --stranded=no SRR3414630.uniq.sam  gencode.vM25.annotation.gtf > SRR3414630.counts\n",
        "!time htseq-count --format=sam --stranded=no SRR3414631.uniq.sam  gencode.vM25.annotation.gtf > SRR3414631.counts\n",
        "!time htseq-count --format=sam --stranded=no SRR3414635.uniq.sam  gencode.vM25.annotation.gtf > SRR3414635.counts\n",
        "!time htseq-count --format=sam --stranded=no SRR3414636.uniq.sam  gencode.vM25.annotation.gtf > SRR3414636.counts\n",
        "!time htseq-count --format=sam --stranded=no SRR3414637.uniq.sam  gencode.vM25.annotation.gtf > SRR3414637.counts"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (1.19.5)\n",
            "Collecting numpy\n",
            "  Downloading numpy-1.21.4-cp37-cp37m-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (15.7 MB)\n",
            "\u001b[K     |████████████████████████████████| 15.7 MB 5.4 MB/s \n",
            "\u001b[?25hInstalling collected packages: numpy\n",
            "  Attempting uninstall: numpy\n",
            "    Found existing installation: numpy 1.19.5\n",
            "    Uninstalling numpy-1.19.5:\n",
            "      Successfully uninstalled numpy-1.19.5\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "yellowbrick 1.3.post1 requires numpy<1.20,>=1.16.0, but you have numpy 1.21.4 which is incompatible.\n",
            "datascience 0.10.6 requires folium==0.2.1, but you have folium 0.8.3 which is incompatible.\n",
            "albumentations 0.1.12 requires imgaug<0.2.7,>=0.2.5, but you have imgaug 0.2.9 which is incompatible.\u001b[0m\n",
            "Successfully installed numpy-1.21.4\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "numpy"
                ]
              }
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "100000 GFF lines processed.\n",
            "200000 GFF lines processed.\n",
            "300000 GFF lines processed.\n",
            "400000 GFF lines processed.\n",
            "500000 GFF lines processed.\n",
            "600000 GFF lines processed.\n",
            "700000 GFF lines processed.\n",
            "800000 GFF lines processed.\n",
            "900000 GFF lines processed.\n",
            "1000000 GFF lines processed.\n",
            "1100000 GFF lines processed.\n",
            "1200000 GFF lines processed.\n",
            "1300000 GFF lines processed.\n",
            "1400000 GFF lines processed.\n",
            "1500000 GFF lines processed.\n",
            "1600000 GFF lines processed.\n",
            "1700000 GFF lines processed.\n",
            "1800000 GFF lines processed.\n",
            "1872052 GFF lines processed.\n",
            "100000 alignment records processed.\n",
            "200000 alignment records processed.\n",
            "300000 alignment records processed.\n",
            "400000 alignment records processed.\n",
            "500000 alignment records processed.\n",
            "600000 alignment records processed.\n",
            "700000 alignment records processed.\n",
            "800000 alignment records processed.\n",
            "900000 alignment records processed.\n",
            "1000000 alignment records processed.\n",
            "1100000 alignment records processed.\n",
            "1200000 alignment records processed.\n",
            "1300000 alignment records processed.\n",
            "1400000 alignment records processed.\n",
            "1500000 alignment records processed.\n",
            "1600000 alignment records processed.\n",
            "1700000 alignment records processed.\n",
            "1800000 alignment records processed.\n",
            "1900000 alignment records processed.\n",
            "2000000 alignment records processed.\n",
            "2100000 alignment records processed.\n",
            "2200000 alignment records processed.\n",
            "2300000 alignment records processed.\n",
            "2400000 alignment records processed.\n",
            "2500000 alignment records processed.\n",
            "2600000 alignment records processed.\n",
            "2700000 alignment records processed.\n",
            "2800000 alignment records processed.\n",
            "2900000 alignment records processed.\n",
            "3000000 alignment records processed.\n",
            "3100000 alignment records processed.\n",
            "3200000 alignment records processed.\n",
            "3300000 alignment records processed.\n",
            "3400000 alignment records processed.\n",
            "3500000 alignment records processed.\n",
            "3600000 alignment records processed.\n",
            "3700000 alignment records processed.\n",
            "3800000 alignment records processed.\n",
            "3900000 alignment records processed.\n",
            "4000000 alignment records processed.\n",
            "4100000 alignment records processed.\n",
            "4200000 alignment records processed.\n",
            "4300000 alignment records processed.\n",
            "4400000 alignment records processed.\n",
            "4500000 alignment records processed.\n",
            "4600000 alignment records processed.\n",
            "4700000 alignment records processed.\n",
            "4800000 alignment records processed.\n",
            "4900000 alignment records processed.\n",
            "5000000 alignment records processed.\n",
            "5100000 alignment records processed.\n",
            "5200000 alignment records processed.\n",
            "5300000 alignment records processed.\n",
            "5400000 alignment records processed.\n",
            "5500000 alignment records processed.\n",
            "5600000 alignment records processed.\n",
            "5700000 alignment records processed.\n",
            "5800000 alignment records processed.\n",
            "5900000 alignment records processed.\n",
            "6000000 alignment records processed.\n",
            "6100000 alignment records processed.\n",
            "6200000 alignment records processed.\n",
            "6300000 alignment records processed.\n",
            "6400000 alignment records processed.\n",
            "6500000 alignment records processed.\n",
            "6600000 alignment records processed.\n",
            "6700000 alignment records processed.\n",
            "6800000 alignment records processed.\n",
            "6900000 alignment records processed.\n",
            "7000000 alignment records processed.\n",
            "7100000 alignment records processed.\n",
            "7200000 alignment records processed.\n",
            "7300000 alignment records processed.\n",
            "7400000 alignment records processed.\n",
            "7500000 alignment records processed.\n",
            "7600000 alignment records processed.\n",
            "7700000 alignment records processed.\n",
            "7800000 alignment records processed.\n",
            "7900000 alignment records processed.\n",
            "8000000 alignment records processed.\n",
            "8100000 alignment records processed.\n",
            "8200000 alignment records processed.\n",
            "8300000 alignment records processed.\n",
            "8400000 alignment records processed.\n",
            "8500000 alignment records processed.\n",
            "8600000 alignment records processed.\n",
            "8700000 alignment records processed.\n",
            "8800000 alignment records processed.\n",
            "8900000 alignment records processed.\n",
            "9000000 alignment records processed.\n",
            "9100000 alignment records processed.\n",
            "9200000 alignment records processed.\n",
            "9300000 alignment records processed.\n",
            "9400000 alignment records processed.\n",
            "9500000 alignment records processed.\n",
            "9600000 alignment records processed.\n",
            "9700000 alignment records processed.\n",
            "9800000 alignment records processed.\n",
            "9900000 alignment records processed.\n",
            "10000000 alignment records processed.\n",
            "10100000 alignment records processed.\n",
            "10200000 alignment records processed.\n",
            "10300000 alignment records processed.\n",
            "10400000 alignment records processed.\n",
            "10500000 alignment records processed.\n",
            "10600000 alignment records processed.\n",
            "10700000 alignment records processed.\n",
            "10800000 alignment records processed.\n",
            "10900000 alignment records processed.\n",
            "11000000 alignment records processed.\n",
            "11100000 alignment records processed.\n",
            "11200000 alignment records processed.\n",
            "11300000 alignment records processed.\n",
            "11400000 alignment records processed.\n",
            "11500000 alignment records processed.\n",
            "11600000 alignment records processed.\n",
            "11700000 alignment records processed.\n",
            "11800000 alignment records processed.\n",
            "11900000 alignment records processed.\n",
            "12000000 alignment records processed.\n",
            "12100000 alignment records processed.\n",
            "12200000 alignment records processed.\n",
            "12300000 alignment records processed.\n",
            "12400000 alignment records processed.\n",
            "12500000 alignment records processed.\n",
            "12600000 alignment records processed.\n",
            "12700000 alignment records processed.\n",
            "12800000 alignment records processed.\n",
            "12900000 alignment records processed.\n",
            "13000000 alignment records processed.\n",
            "13100000 alignment records processed.\n",
            "13200000 alignment records processed.\n",
            "13300000 alignment records processed.\n",
            "13400000 alignment records processed.\n",
            "13500000 alignment records processed.\n",
            "13600000 alignment records processed.\n",
            "13700000 alignment records processed.\n",
            "13800000 alignment records processed.\n",
            "13900000 alignment records processed.\n",
            "14000000 alignment records processed.\n",
            "14100000 alignment records processed.\n",
            "14200000 alignment records processed.\n",
            "14300000 alignment records processed.\n",
            "14400000 alignment records processed.\n",
            "14500000 alignment records processed.\n",
            "14600000 alignment records processed.\n",
            "14700000 alignment records processed.\n",
            "14800000 alignment records processed.\n",
            "14900000 alignment records processed.\n",
            "15000000 alignment records processed.\n",
            "15100000 alignment records processed.\n",
            "15200000 alignment records processed.\n",
            "15300000 alignment records processed.\n",
            "15400000 alignment records processed.\n",
            "15500000 alignment records processed.\n",
            "15600000 alignment records processed.\n",
            "15700000 alignment records processed.\n",
            "15800000 alignment records processed.\n",
            "15900000 alignment records processed.\n",
            "16000000 alignment records processed.\n",
            "16100000 alignment records processed.\n",
            "16200000 alignment records processed.\n",
            "16300000 alignment records processed.\n",
            "16400000 alignment records processed.\n",
            "16500000 alignment records processed.\n",
            "16600000 alignment records processed.\n",
            "16700000 alignment records processed.\n",
            "16800000 alignment records processed.\n",
            "16900000 alignment records processed.\n",
            "17000000 alignment records processed.\n",
            "17100000 alignment records processed.\n",
            "17200000 alignment records processed.\n",
            "17300000 alignment records processed.\n",
            "17400000 alignment records processed.\n",
            "17500000 alignment records processed.\n",
            "17600000 alignment records processed.\n",
            "17700000 alignment records processed.\n",
            "17800000 alignment records processed.\n",
            "17900000 alignment records processed.\n",
            "18000000 alignment records processed.\n",
            "18100000 alignment records processed.\n",
            "18200000 alignment records processed.\n",
            "18300000 alignment records processed.\n",
            "18375888 alignment records processed.\n",
            "\n",
            "real\t18m57.300s\n",
            "user\t18m47.755s\n",
            "sys\t0m7.994s\n",
            "100000 GFF lines processed.\n",
            "200000 GFF lines processed.\n",
            "300000 GFF lines processed.\n",
            "400000 GFF lines processed.\n",
            "500000 GFF lines processed.\n",
            "600000 GFF lines processed.\n",
            "700000 GFF lines processed.\n",
            "800000 GFF lines processed.\n",
            "900000 GFF lines processed.\n",
            "1000000 GFF lines processed.\n",
            "1100000 GFF lines processed.\n",
            "1200000 GFF lines processed.\n",
            "1300000 GFF lines processed.\n",
            "1400000 GFF lines processed.\n",
            "1500000 GFF lines processed.\n",
            "1600000 GFF lines processed.\n",
            "1700000 GFF lines processed.\n",
            "1800000 GFF lines processed.\n",
            "1872052 GFF lines processed.\n",
            "100000 alignment records processed.\n",
            "200000 alignment records processed.\n",
            "300000 alignment records processed.\n",
            "400000 alignment records processed.\n",
            "500000 alignment records processed.\n",
            "600000 alignment records processed.\n",
            "700000 alignment records processed.\n",
            "800000 alignment records processed.\n",
            "900000 alignment records processed.\n",
            "1000000 alignment records processed.\n",
            "1100000 alignment records processed.\n",
            "1200000 alignment records processed.\n",
            "1300000 alignment records processed.\n",
            "1400000 alignment records processed.\n",
            "1500000 alignment records processed.\n",
            "1600000 alignment records processed.\n",
            "1700000 alignment records processed.\n",
            "1800000 alignment records processed.\n",
            "1900000 alignment records processed.\n",
            "2000000 alignment records processed.\n",
            "2100000 alignment records processed.\n",
            "2200000 alignment records processed.\n",
            "2300000 alignment records processed.\n",
            "2400000 alignment records processed.\n",
            "2500000 alignment records processed.\n",
            "2600000 alignment records processed.\n",
            "2700000 alignment records processed.\n",
            "2800000 alignment records processed.\n",
            "2900000 alignment records processed.\n",
            "3000000 alignment records processed.\n",
            "3100000 alignment records processed.\n",
            "3200000 alignment records processed.\n",
            "3300000 alignment records processed.\n",
            "3400000 alignment records processed.\n",
            "3500000 alignment records processed.\n",
            "3600000 alignment records processed.\n",
            "3700000 alignment records processed.\n",
            "3800000 alignment records processed.\n",
            "3900000 alignment records processed.\n",
            "4000000 alignment records processed.\n",
            "4100000 alignment records processed.\n",
            "4200000 alignment records processed.\n",
            "4300000 alignment records processed.\n",
            "4400000 alignment records processed.\n",
            "4500000 alignment records processed.\n",
            "4600000 alignment records processed.\n",
            "4700000 alignment records processed.\n",
            "4800000 alignment records processed.\n",
            "4900000 alignment records processed.\n",
            "5000000 alignment records processed.\n",
            "5100000 alignment records processed.\n",
            "5200000 alignment records processed.\n",
            "5300000 alignment records processed.\n",
            "5400000 alignment records processed.\n",
            "5500000 alignment records processed.\n",
            "5600000 alignment records processed.\n",
            "5700000 alignment records processed.\n",
            "5800000 alignment records processed.\n",
            "5900000 alignment records processed.\n",
            "6000000 alignment records processed.\n",
            "6100000 alignment records processed.\n",
            "6200000 alignment records processed.\n",
            "6300000 alignment records processed.\n",
            "6400000 alignment records processed.\n",
            "6500000 alignment records processed.\n",
            "6600000 alignment records processed.\n",
            "6700000 alignment records processed.\n",
            "6800000 alignment records processed.\n",
            "6900000 alignment records processed.\n",
            "7000000 alignment records processed.\n",
            "7100000 alignment records processed.\n",
            "7200000 alignment records processed.\n",
            "7300000 alignment records processed.\n",
            "7400000 alignment records processed.\n",
            "7500000 alignment records processed.\n",
            "7600000 alignment records processed.\n",
            "7700000 alignment records processed.\n",
            "7800000 alignment records processed.\n",
            "7900000 alignment records processed.\n",
            "8000000 alignment records processed.\n",
            "8100000 alignment records processed.\n",
            "8200000 alignment records processed.\n",
            "8300000 alignment records processed.\n",
            "8400000 alignment records processed.\n",
            "8500000 alignment records processed.\n",
            "8600000 alignment records processed.\n",
            "8700000 alignment records processed.\n",
            "8800000 alignment records processed.\n",
            "8900000 alignment records processed.\n",
            "9000000 alignment records processed.\n",
            "9100000 alignment records processed.\n",
            "9200000 alignment records processed.\n",
            "9300000 alignment records processed.\n",
            "9400000 alignment records processed.\n",
            "9500000 alignment records processed.\n",
            "9600000 alignment records processed.\n",
            "9700000 alignment records processed.\n",
            "9800000 alignment records processed.\n",
            "9900000 alignment records processed.\n",
            "10000000 alignment records processed.\n",
            "10100000 alignment records processed.\n",
            "10200000 alignment records processed.\n",
            "10300000 alignment records processed.\n",
            "10400000 alignment records processed.\n",
            "10500000 alignment records processed.\n",
            "10600000 alignment records processed.\n",
            "10700000 alignment records processed.\n",
            "10800000 alignment records processed.\n",
            "10900000 alignment records processed.\n",
            "11000000 alignment records processed.\n",
            "11100000 alignment records processed.\n",
            "11200000 alignment records processed.\n",
            "11300000 alignment records processed.\n",
            "11400000 alignment records processed.\n",
            "11500000 alignment records processed.\n",
            "11600000 alignment records processed.\n",
            "11700000 alignment records processed.\n",
            "11800000 alignment records processed.\n",
            "11900000 alignment records processed.\n",
            "12000000 alignment records processed.\n",
            "12100000 alignment records processed.\n",
            "12200000 alignment records processed.\n",
            "12300000 alignment records processed.\n",
            "12400000 alignment records processed.\n",
            "12500000 alignment records processed.\n",
            "12600000 alignment records processed.\n",
            "12700000 alignment records processed.\n",
            "12800000 alignment records processed.\n",
            "12900000 alignment records processed.\n",
            "13000000 alignment records processed.\n",
            "13100000 alignment records processed.\n",
            "13186139 alignment records processed.\n",
            "\n",
            "real\t14m5.789s\n",
            "user\t13m58.924s\n",
            "sys\t0m5.905s\n",
            "100000 GFF lines processed.\n",
            "200000 GFF lines processed.\n",
            "300000 GFF lines processed.\n",
            "400000 GFF lines processed.\n",
            "500000 GFF lines processed.\n",
            "600000 GFF lines processed.\n",
            "700000 GFF lines processed.\n",
            "800000 GFF lines processed.\n",
            "900000 GFF lines processed.\n",
            "1000000 GFF lines processed.\n",
            "1100000 GFF lines processed.\n",
            "1200000 GFF lines processed.\n",
            "1300000 GFF lines processed.\n",
            "1400000 GFF lines processed.\n",
            "1500000 GFF lines processed.\n",
            "1600000 GFF lines processed.\n",
            "1700000 GFF lines processed.\n",
            "1800000 GFF lines processed.\n",
            "1872052 GFF lines processed.\n",
            "100000 alignment records processed.\n",
            "200000 alignment records processed.\n",
            "300000 alignment records processed.\n",
            "400000 alignment records processed.\n",
            "500000 alignment records processed.\n",
            "600000 alignment records processed.\n",
            "700000 alignment records processed.\n",
            "800000 alignment records processed.\n",
            "900000 alignment records processed.\n",
            "1000000 alignment records processed.\n",
            "1100000 alignment records processed.\n",
            "1200000 alignment records processed.\n",
            "1300000 alignment records processed.\n",
            "1400000 alignment records processed.\n",
            "1500000 alignment records processed.\n",
            "1600000 alignment records processed.\n",
            "1700000 alignment records processed.\n",
            "1800000 alignment records processed.\n",
            "1900000 alignment records processed.\n",
            "2000000 alignment records processed.\n",
            "2100000 alignment records processed.\n",
            "2200000 alignment records processed.\n",
            "2300000 alignment records processed.\n",
            "2400000 alignment records processed.\n",
            "2500000 alignment records processed.\n",
            "2600000 alignment records processed.\n",
            "2700000 alignment records processed.\n",
            "2800000 alignment records processed.\n",
            "2900000 alignment records processed.\n",
            "3000000 alignment records processed.\n",
            "3100000 alignment records processed.\n",
            "3200000 alignment records processed.\n",
            "3300000 alignment records processed.\n",
            "3400000 alignment records processed.\n",
            "3500000 alignment records processed.\n",
            "3600000 alignment records processed.\n",
            "3700000 alignment records processed.\n",
            "3800000 alignment records processed.\n",
            "3900000 alignment records processed.\n",
            "4000000 alignment records processed.\n",
            "4100000 alignment records processed.\n",
            "4200000 alignment records processed.\n",
            "4300000 alignment records processed.\n",
            "4400000 alignment records processed.\n",
            "4500000 alignment records processed.\n",
            "4600000 alignment records processed.\n",
            "4700000 alignment records processed.\n",
            "4800000 alignment records processed.\n",
            "4900000 alignment records processed.\n",
            "5000000 alignment records processed.\n",
            "5100000 alignment records processed.\n",
            "5200000 alignment records processed.\n",
            "5300000 alignment records processed.\n",
            "5400000 alignment records processed.\n",
            "5500000 alignment records processed.\n",
            "5600000 alignment records processed.\n",
            "5700000 alignment records processed.\n",
            "5800000 alignment records processed.\n",
            "5900000 alignment records processed.\n",
            "6000000 alignment records processed.\n",
            "6100000 alignment records processed.\n",
            "6200000 alignment records processed.\n",
            "6300000 alignment records processed.\n",
            "6400000 alignment records processed.\n",
            "6500000 alignment records processed.\n",
            "6600000 alignment records processed.\n",
            "6700000 alignment records processed.\n",
            "6800000 alignment records processed.\n",
            "6900000 alignment records processed.\n",
            "7000000 alignment records processed.\n",
            "7100000 alignment records processed.\n",
            "7200000 alignment records processed.\n",
            "7300000 alignment records processed.\n",
            "7400000 alignment records processed.\n",
            "7500000 alignment records processed.\n",
            "7600000 alignment records processed.\n",
            "7700000 alignment records processed.\n",
            "7800000 alignment records processed.\n",
            "7900000 alignment records processed.\n",
            "8000000 alignment records processed.\n",
            "8100000 alignment records processed.\n",
            "8200000 alignment records processed.\n",
            "8300000 alignment records processed.\n",
            "8400000 alignment records processed.\n",
            "8500000 alignment records processed.\n",
            "8600000 alignment records processed.\n",
            "8700000 alignment records processed.\n",
            "8800000 alignment records processed.\n",
            "8900000 alignment records processed.\n",
            "9000000 alignment records processed.\n",
            "9100000 alignment records processed.\n",
            "9200000 alignment records processed.\n",
            "9300000 alignment records processed.\n",
            "9400000 alignment records processed.\n",
            "9500000 alignment records processed.\n",
            "9600000 alignment records processed.\n",
            "9700000 alignment records processed.\n",
            "9800000 alignment records processed.\n",
            "9900000 alignment records processed.\n",
            "10000000 alignment records processed.\n",
            "10100000 alignment records processed.\n",
            "10200000 alignment records processed.\n",
            "10300000 alignment records processed.\n",
            "10400000 alignment records processed.\n",
            "10500000 alignment records processed.\n",
            "10600000 alignment records processed.\n",
            "10700000 alignment records processed.\n",
            "10800000 alignment records processed.\n",
            "10900000 alignment records processed.\n",
            "11000000 alignment records processed.\n",
            "11100000 alignment records processed.\n",
            "11200000 alignment records processed.\n",
            "11300000 alignment records processed.\n",
            "11400000 alignment records processed.\n",
            "11500000 alignment records processed.\n",
            "11600000 alignment records processed.\n",
            "11700000 alignment records processed.\n",
            "11800000 alignment records processed.\n",
            "11900000 alignment records processed.\n",
            "12000000 alignment records processed.\n",
            "12100000 alignment records processed.\n",
            "12200000 alignment records processed.\n",
            "12300000 alignment records processed.\n",
            "12400000 alignment records processed.\n",
            "12500000 alignment records processed.\n",
            "12600000 alignment records processed.\n",
            "12700000 alignment records processed.\n",
            "12800000 alignment records processed.\n",
            "12900000 alignment records processed.\n",
            "13000000 alignment records processed.\n",
            "13100000 alignment records processed.\n",
            "13200000 alignment records processed.\n",
            "13300000 alignment records processed.\n",
            "13400000 alignment records processed.\n",
            "13500000 alignment records processed.\n",
            "13600000 alignment records processed.\n",
            "13700000 alignment records processed.\n",
            "13800000 alignment records processed.\n",
            "13900000 alignment records processed.\n",
            "14000000 alignment records processed.\n",
            "14100000 alignment records processed.\n",
            "14200000 alignment records processed.\n",
            "14300000 alignment records processed.\n",
            "14400000 alignment records processed.\n",
            "14500000 alignment records processed.\n",
            "14600000 alignment records processed.\n",
            "14700000 alignment records processed.\n",
            "14800000 alignment records processed.\n",
            "14900000 alignment records processed.\n",
            "15000000 alignment records processed.\n",
            "15100000 alignment records processed.\n",
            "15200000 alignment records processed.\n",
            "15300000 alignment records processed.\n",
            "15400000 alignment records processed.\n",
            "15500000 alignment records processed.\n",
            "15600000 alignment records processed.\n",
            "15700000 alignment records processed.\n",
            "15800000 alignment records processed.\n",
            "15900000 alignment records processed.\n",
            "16000000 alignment records processed.\n",
            "16100000 alignment records processed.\n",
            "16200000 alignment records processed.\n",
            "16300000 alignment records processed.\n",
            "16400000 alignment records processed.\n",
            "16500000 alignment records processed.\n",
            "16600000 alignment records processed.\n",
            "16700000 alignment records processed.\n",
            "16800000 alignment records processed.\n",
            "16900000 alignment records processed.\n",
            "17000000 alignment records processed.\n",
            "17100000 alignment records processed.\n",
            "17200000 alignment records processed.\n",
            "17300000 alignment records processed.\n",
            "17400000 alignment records processed.\n",
            "17500000 alignment records processed.\n",
            "17600000 alignment records processed.\n",
            "17700000 alignment records processed.\n",
            "17800000 alignment records processed.\n",
            "17900000 alignment records processed.\n",
            "18000000 alignment records processed.\n",
            "18100000 alignment records processed.\n",
            "18200000 alignment records processed.\n",
            "18300000 alignment records processed.\n",
            "18400000 alignment records processed.\n",
            "18500000 alignment records processed.\n",
            "18600000 alignment records processed.\n",
            "18700000 alignment records processed.\n",
            "18800000 alignment records processed.\n",
            "18900000 alignment records processed.\n",
            "19000000 alignment records processed.\n",
            "19100000 alignment records processed.\n",
            "19200000 alignment records processed.\n",
            "19300000 alignment records processed.\n",
            "19400000 alignment records processed.\n",
            "19500000 alignment records processed.\n",
            "19600000 alignment records processed.\n",
            "19700000 alignment records processed.\n",
            "19800000 alignment records processed.\n",
            "19900000 alignment records processed.\n",
            "20000000 alignment records processed.\n",
            "20100000 alignment records processed.\n",
            "20200000 alignment records processed.\n",
            "20300000 alignment records processed.\n",
            "20400000 alignment records processed.\n",
            "20500000 alignment records processed.\n",
            "20600000 alignment records processed.\n",
            "20700000 alignment records processed.\n",
            "20800000 alignment records processed.\n",
            "20900000 alignment records processed.\n",
            "20928945 alignment records processed.\n",
            "\n",
            "real\t21m28.604s\n",
            "user\t21m19.241s\n",
            "sys\t0m8.198s\n",
            "100000 GFF lines processed.\n",
            "200000 GFF lines processed.\n",
            "300000 GFF lines processed.\n",
            "400000 GFF lines processed.\n",
            "500000 GFF lines processed.\n",
            "600000 GFF lines processed.\n",
            "700000 GFF lines processed.\n",
            "800000 GFF lines processed.\n",
            "900000 GFF lines processed.\n",
            "1000000 GFF lines processed.\n",
            "1100000 GFF lines processed.\n",
            "1200000 GFF lines processed.\n",
            "1300000 GFF lines processed.\n",
            "1400000 GFF lines processed.\n",
            "1500000 GFF lines processed.\n",
            "1600000 GFF lines processed.\n",
            "1700000 GFF lines processed.\n",
            "1800000 GFF lines processed.\n",
            "1872052 GFF lines processed.\n",
            "100000 alignment records processed.\n",
            "200000 alignment records processed.\n",
            "300000 alignment records processed.\n",
            "400000 alignment records processed.\n",
            "500000 alignment records processed.\n",
            "600000 alignment records processed.\n",
            "700000 alignment records processed.\n",
            "800000 alignment records processed.\n",
            "900000 alignment records processed.\n",
            "1000000 alignment records processed.\n",
            "1100000 alignment records processed.\n",
            "1200000 alignment records processed.\n",
            "1300000 alignment records processed.\n",
            "1400000 alignment records processed.\n",
            "1500000 alignment records processed.\n",
            "1600000 alignment records processed.\n",
            "1700000 alignment records processed.\n",
            "1800000 alignment records processed.\n",
            "1900000 alignment records processed.\n",
            "2000000 alignment records processed.\n",
            "2100000 alignment records processed.\n",
            "2200000 alignment records processed.\n",
            "2300000 alignment records processed.\n",
            "2400000 alignment records processed.\n",
            "2500000 alignment records processed.\n",
            "2600000 alignment records processed.\n",
            "2700000 alignment records processed.\n",
            "2800000 alignment records processed.\n",
            "2900000 alignment records processed.\n",
            "3000000 alignment records processed.\n",
            "3100000 alignment records processed.\n",
            "3200000 alignment records processed.\n",
            "3300000 alignment records processed.\n",
            "3400000 alignment records processed.\n",
            "3500000 alignment records processed.\n",
            "3600000 alignment records processed.\n",
            "3700000 alignment records processed.\n",
            "3800000 alignment records processed.\n",
            "3900000 alignment records processed.\n",
            "4000000 alignment records processed.\n",
            "4100000 alignment records processed.\n",
            "4200000 alignment records processed.\n",
            "4300000 alignment records processed.\n",
            "4400000 alignment records processed.\n",
            "4500000 alignment records processed.\n",
            "4600000 alignment records processed.\n",
            "4700000 alignment records processed.\n",
            "4800000 alignment records processed.\n",
            "4900000 alignment records processed.\n",
            "5000000 alignment records processed.\n",
            "5100000 alignment records processed.\n",
            "5200000 alignment records processed.\n",
            "5300000 alignment records processed.\n",
            "5400000 alignment records processed.\n",
            "5500000 alignment records processed.\n",
            "5600000 alignment records processed.\n",
            "5700000 alignment records processed.\n",
            "5800000 alignment records processed.\n",
            "5900000 alignment records processed.\n",
            "6000000 alignment records processed.\n",
            "6100000 alignment records processed.\n",
            "6200000 alignment records processed.\n",
            "6300000 alignment records processed.\n",
            "6400000 alignment records processed.\n",
            "6500000 alignment records processed.\n",
            "6600000 alignment records processed.\n",
            "6700000 alignment records processed.\n",
            "6800000 alignment records processed.\n",
            "6900000 alignment records processed.\n",
            "7000000 alignment records processed.\n",
            "7100000 alignment records processed.\n",
            "7200000 alignment records processed.\n",
            "7300000 alignment records processed.\n",
            "7400000 alignment records processed.\n",
            "7500000 alignment records processed.\n",
            "7600000 alignment records processed.\n",
            "7700000 alignment records processed.\n",
            "7800000 alignment records processed.\n",
            "7900000 alignment records processed.\n",
            "8000000 alignment records processed.\n",
            "8100000 alignment records processed.\n",
            "8200000 alignment records processed.\n",
            "8300000 alignment records processed.\n",
            "8400000 alignment records processed.\n",
            "8500000 alignment records processed.\n",
            "8600000 alignment records processed.\n",
            "8700000 alignment records processed.\n",
            "8800000 alignment records processed.\n",
            "8900000 alignment records processed.\n",
            "9000000 alignment records processed.\n",
            "9100000 alignment records processed.\n",
            "9200000 alignment records processed.\n",
            "9300000 alignment records processed.\n",
            "9400000 alignment records processed.\n",
            "9500000 alignment records processed.\n",
            "9600000 alignment records processed.\n",
            "9700000 alignment records processed.\n",
            "9800000 alignment records processed.\n",
            "9900000 alignment records processed.\n",
            "10000000 alignment records processed.\n",
            "10100000 alignment records processed.\n",
            "10200000 alignment records processed.\n",
            "10300000 alignment records processed.\n",
            "10400000 alignment records processed.\n",
            "10500000 alignment records processed.\n",
            "10600000 alignment records processed.\n",
            "10700000 alignment records processed.\n",
            "10800000 alignment records processed.\n",
            "10900000 alignment records processed.\n",
            "11000000 alignment records processed.\n",
            "11100000 alignment records processed.\n",
            "11200000 alignment records processed.\n",
            "11300000 alignment records processed.\n",
            "11400000 alignment records processed.\n",
            "11500000 alignment records processed.\n",
            "11600000 alignment records processed.\n",
            "11700000 alignment records processed.\n",
            "11800000 alignment records processed.\n",
            "11900000 alignment records processed.\n",
            "12000000 alignment records processed.\n",
            "12100000 alignment records processed.\n",
            "12200000 alignment records processed.\n",
            "12300000 alignment records processed.\n",
            "12400000 alignment records processed.\n",
            "12500000 alignment records processed.\n",
            "12600000 alignment records processed.\n",
            "12700000 alignment records processed.\n",
            "12800000 alignment records processed.\n",
            "12900000 alignment records processed.\n",
            "13000000 alignment records processed.\n",
            "13100000 alignment records processed.\n",
            "13200000 alignment records processed.\n",
            "13300000 alignment records processed.\n",
            "13400000 alignment records processed.\n",
            "13500000 alignment records processed.\n",
            "13600000 alignment records processed.\n",
            "13700000 alignment records processed.\n",
            "13800000 alignment records processed.\n",
            "13900000 alignment records processed.\n",
            "14000000 alignment records processed.\n",
            "14100000 alignment records processed.\n",
            "14200000 alignment records processed.\n",
            "14300000 alignment records processed.\n",
            "14400000 alignment records processed.\n",
            "14500000 alignment records processed.\n",
            "14600000 alignment records processed.\n",
            "14700000 alignment records processed.\n",
            "14800000 alignment records processed.\n",
            "14900000 alignment records processed.\n",
            "15000000 alignment records processed.\n",
            "15100000 alignment records processed.\n",
            "15200000 alignment records processed.\n",
            "15300000 alignment records processed.\n",
            "15400000 alignment records processed.\n",
            "15500000 alignment records processed.\n",
            "15600000 alignment records processed.\n",
            "15700000 alignment records processed.\n",
            "15800000 alignment records processed.\n",
            "15900000 alignment records processed.\n",
            "16000000 alignment records processed.\n",
            "16100000 alignment records processed.\n",
            "16200000 alignment records processed.\n",
            "16300000 alignment records processed.\n",
            "16400000 alignment records processed.\n",
            "16500000 alignment records processed.\n",
            "16600000 alignment records processed.\n",
            "16700000 alignment records processed.\n",
            "16800000 alignment records processed.\n",
            "16900000 alignment records processed.\n",
            "17000000 alignment records processed.\n",
            "17100000 alignment records processed.\n",
            "17200000 alignment records processed.\n",
            "17300000 alignment records processed.\n",
            "17400000 alignment records processed.\n",
            "17500000 alignment records processed.\n",
            "17600000 alignment records processed.\n",
            "17700000 alignment records processed.\n",
            "17800000 alignment records processed.\n",
            "17900000 alignment records processed.\n",
            "18000000 alignment records processed.\n",
            "18100000 alignment records processed.\n",
            "18200000 alignment records processed.\n",
            "18300000 alignment records processed.\n",
            "18400000 alignment records processed.\n",
            "18428317 alignment records processed.\n",
            "\n",
            "real\t19m12.107s\n",
            "user\t19m3.561s\n",
            "sys\t0m7.599s\n",
            "100000 GFF lines processed.\n",
            "200000 GFF lines processed.\n",
            "300000 GFF lines processed.\n",
            "400000 GFF lines processed.\n",
            "500000 GFF lines processed.\n",
            "600000 GFF lines processed.\n",
            "700000 GFF lines processed.\n",
            "800000 GFF lines processed.\n",
            "900000 GFF lines processed.\n",
            "1000000 GFF lines processed.\n",
            "1100000 GFF lines processed.\n",
            "1200000 GFF lines processed.\n",
            "1300000 GFF lines processed.\n",
            "1400000 GFF lines processed.\n",
            "1500000 GFF lines processed.\n",
            "1600000 GFF lines processed.\n",
            "1700000 GFF lines processed.\n",
            "1800000 GFF lines processed.\n",
            "1872052 GFF lines processed.\n",
            "100000 alignment records processed.\n",
            "200000 alignment records processed.\n",
            "300000 alignment records processed.\n",
            "400000 alignment records processed.\n",
            "500000 alignment records processed.\n",
            "600000 alignment records processed.\n",
            "700000 alignment records processed.\n",
            "800000 alignment records processed.\n",
            "900000 alignment records processed.\n",
            "1000000 alignment records processed.\n",
            "1100000 alignment records processed.\n",
            "1200000 alignment records processed.\n",
            "1300000 alignment records processed.\n",
            "1400000 alignment records processed.\n",
            "1500000 alignment records processed.\n",
            "1600000 alignment records processed.\n",
            "1700000 alignment records processed.\n",
            "1800000 alignment records processed.\n",
            "1900000 alignment records processed.\n",
            "2000000 alignment records processed.\n",
            "2100000 alignment records processed.\n",
            "2200000 alignment records processed.\n",
            "2300000 alignment records processed.\n",
            "2400000 alignment records processed.\n",
            "2500000 alignment records processed.\n",
            "2600000 alignment records processed.\n",
            "2700000 alignment records processed.\n",
            "2800000 alignment records processed.\n",
            "2900000 alignment records processed.\n",
            "3000000 alignment records processed.\n",
            "3100000 alignment records processed.\n",
            "3200000 alignment records processed.\n",
            "3300000 alignment records processed.\n",
            "3400000 alignment records processed.\n",
            "3500000 alignment records processed.\n",
            "3600000 alignment records processed.\n",
            "3700000 alignment records processed.\n",
            "3800000 alignment records processed.\n",
            "3900000 alignment records processed.\n",
            "4000000 alignment records processed.\n",
            "4100000 alignment records processed.\n",
            "4200000 alignment records processed.\n",
            "4300000 alignment records processed.\n",
            "4400000 alignment records processed.\n",
            "4500000 alignment records processed.\n",
            "4600000 alignment records processed.\n",
            "4700000 alignment records processed.\n",
            "4800000 alignment records processed.\n",
            "4900000 alignment records processed.\n",
            "5000000 alignment records processed.\n",
            "5100000 alignment records processed.\n",
            "5200000 alignment records processed.\n",
            "5300000 alignment records processed.\n",
            "5400000 alignment records processed.\n",
            "5500000 alignment records processed.\n",
            "5600000 alignment records processed.\n",
            "5700000 alignment records processed.\n",
            "5800000 alignment records processed.\n",
            "5900000 alignment records processed.\n",
            "6000000 alignment records processed.\n",
            "6100000 alignment records processed.\n",
            "6200000 alignment records processed.\n",
            "6300000 alignment records processed.\n",
            "6400000 alignment records processed.\n",
            "6500000 alignment records processed.\n",
            "6600000 alignment records processed.\n",
            "6700000 alignment records processed.\n",
            "6800000 alignment records processed.\n",
            "6900000 alignment records processed.\n",
            "7000000 alignment records processed.\n",
            "7100000 alignment records processed.\n",
            "7200000 alignment records processed.\n",
            "7300000 alignment records processed.\n",
            "7400000 alignment records processed.\n",
            "7500000 alignment records processed.\n",
            "7600000 alignment records processed.\n",
            "7700000 alignment records processed.\n",
            "7800000 alignment records processed.\n",
            "7900000 alignment records processed.\n",
            "8000000 alignment records processed.\n",
            "8100000 alignment records processed.\n",
            "8200000 alignment records processed.\n",
            "8300000 alignment records processed.\n",
            "8400000 alignment records processed.\n",
            "8500000 alignment records processed.\n",
            "8600000 alignment records processed.\n",
            "8700000 alignment records processed.\n",
            "8800000 alignment records processed.\n",
            "8900000 alignment records processed.\n",
            "9000000 alignment records processed.\n",
            "9100000 alignment records processed.\n",
            "9200000 alignment records processed.\n",
            "9300000 alignment records processed.\n",
            "9400000 alignment records processed.\n",
            "9500000 alignment records processed.\n",
            "9600000 alignment records processed.\n",
            "9700000 alignment records processed.\n",
            "9800000 alignment records processed.\n",
            "9900000 alignment records processed.\n",
            "10000000 alignment records processed.\n",
            "10100000 alignment records processed.\n",
            "10200000 alignment records processed.\n",
            "10300000 alignment records processed.\n",
            "10400000 alignment records processed.\n",
            "10500000 alignment records processed.\n",
            "10600000 alignment records processed.\n",
            "10700000 alignment records processed.\n",
            "10800000 alignment records processed.\n",
            "10900000 alignment records processed.\n",
            "11000000 alignment records processed.\n",
            "11100000 alignment records processed.\n",
            "11200000 alignment records processed.\n",
            "11300000 alignment records processed.\n",
            "11400000 alignment records processed.\n",
            "11500000 alignment records processed.\n",
            "11600000 alignment records processed.\n",
            "11700000 alignment records processed.\n",
            "11800000 alignment records processed.\n",
            "11900000 alignment records processed.\n",
            "12000000 alignment records processed.\n",
            "12100000 alignment records processed.\n",
            "12200000 alignment records processed.\n",
            "12300000 alignment records processed.\n",
            "12400000 alignment records processed.\n",
            "12500000 alignment records processed.\n",
            "12600000 alignment records processed.\n",
            "12700000 alignment records processed.\n",
            "12800000 alignment records processed.\n",
            "12900000 alignment records processed.\n",
            "13000000 alignment records processed.\n",
            "13100000 alignment records processed.\n",
            "13200000 alignment records processed.\n",
            "13300000 alignment records processed.\n",
            "13400000 alignment records processed.\n",
            "13500000 alignment records processed.\n",
            "13600000 alignment records processed.\n",
            "13700000 alignment records processed.\n",
            "13800000 alignment records processed.\n",
            "13900000 alignment records processed.\n",
            "14000000 alignment records processed.\n",
            "14100000 alignment records processed.\n",
            "14200000 alignment records processed.\n",
            "14300000 alignment records processed.\n",
            "14400000 alignment records processed.\n",
            "14500000 alignment records processed.\n",
            "14600000 alignment records processed.\n",
            "14700000 alignment records processed.\n",
            "14800000 alignment records processed.\n",
            "14900000 alignment records processed.\n",
            "15000000 alignment records processed.\n",
            "15100000 alignment records processed.\n",
            "15200000 alignment records processed.\n",
            "15300000 alignment records processed.\n",
            "15400000 alignment records processed.\n",
            "15500000 alignment records processed.\n",
            "15600000 alignment records processed.\n",
            "15700000 alignment records processed.\n",
            "15800000 alignment records processed.\n",
            "15900000 alignment records processed.\n",
            "16000000 alignment records processed.\n",
            "16100000 alignment records processed.\n",
            "16200000 alignment records processed.\n",
            "16300000 alignment records processed.\n",
            "16400000 alignment records processed.\n",
            "16500000 alignment records processed.\n",
            "16600000 alignment records processed.\n",
            "16700000 alignment records processed.\n",
            "16800000 alignment records processed.\n",
            "16900000 alignment records processed.\n",
            "17000000 alignment records processed.\n",
            "17100000 alignment records processed.\n",
            "17200000 alignment records processed.\n",
            "17300000 alignment records processed.\n",
            "17400000 alignment records processed.\n",
            "17500000 alignment records processed.\n",
            "17600000 alignment records processed.\n",
            "17700000 alignment records processed.\n",
            "17800000 alignment records processed.\n",
            "17825380 alignment records processed.\n",
            "\n",
            "real\t18m26.191s\n",
            "user\t18m16.512s\n",
            "sys\t0m7.760s\n",
            "100000 GFF lines processed.\n",
            "200000 GFF lines processed.\n",
            "300000 GFF lines processed.\n",
            "400000 GFF lines processed.\n",
            "500000 GFF lines processed.\n",
            "600000 GFF lines processed.\n",
            "700000 GFF lines processed.\n",
            "800000 GFF lines processed.\n",
            "900000 GFF lines processed.\n",
            "1000000 GFF lines processed.\n",
            "1100000 GFF lines processed.\n",
            "1200000 GFF lines processed.\n",
            "1300000 GFF lines processed.\n",
            "1400000 GFF lines processed.\n",
            "1500000 GFF lines processed.\n",
            "1600000 GFF lines processed.\n",
            "1700000 GFF lines processed.\n",
            "1800000 GFF lines processed.\n",
            "1872052 GFF lines processed.\n",
            "100000 alignment records processed.\n",
            "200000 alignment records processed.\n",
            "300000 alignment records processed.\n",
            "400000 alignment records processed.\n",
            "500000 alignment records processed.\n",
            "600000 alignment records processed.\n",
            "700000 alignment records processed.\n",
            "800000 alignment records processed.\n",
            "900000 alignment records processed.\n",
            "1000000 alignment records processed.\n",
            "1100000 alignment records processed.\n",
            "1200000 alignment records processed.\n",
            "1300000 alignment records processed.\n",
            "1400000 alignment records processed.\n",
            "1500000 alignment records processed.\n",
            "1600000 alignment records processed.\n",
            "1700000 alignment records processed.\n",
            "1800000 alignment records processed.\n",
            "1900000 alignment records processed.\n",
            "2000000 alignment records processed.\n",
            "2100000 alignment records processed.\n",
            "2200000 alignment records processed.\n",
            "2300000 alignment records processed.\n",
            "2400000 alignment records processed.\n",
            "2500000 alignment records processed.\n",
            "2600000 alignment records processed.\n",
            "2700000 alignment records processed.\n",
            "2800000 alignment records processed.\n",
            "2900000 alignment records processed.\n",
            "3000000 alignment records processed.\n",
            "3100000 alignment records processed.\n",
            "3200000 alignment records processed.\n",
            "3300000 alignment records processed.\n",
            "3400000 alignment records processed.\n",
            "3500000 alignment records processed.\n",
            "3600000 alignment records processed.\n",
            "3700000 alignment records processed.\n",
            "3800000 alignment records processed.\n",
            "3900000 alignment records processed.\n",
            "4000000 alignment records processed.\n",
            "4100000 alignment records processed.\n",
            "4200000 alignment records processed.\n",
            "4300000 alignment records processed.\n",
            "4400000 alignment records processed.\n",
            "4500000 alignment records processed.\n",
            "4600000 alignment records processed.\n",
            "4700000 alignment records processed.\n",
            "4800000 alignment records processed.\n",
            "4900000 alignment records processed.\n",
            "5000000 alignment records processed.\n",
            "5100000 alignment records processed.\n",
            "5200000 alignment records processed.\n",
            "5300000 alignment records processed.\n",
            "5400000 alignment records processed.\n",
            "5500000 alignment records processed.\n",
            "5600000 alignment records processed.\n",
            "5700000 alignment records processed.\n",
            "5800000 alignment records processed.\n",
            "5900000 alignment records processed.\n",
            "6000000 alignment records processed.\n",
            "6100000 alignment records processed.\n",
            "6200000 alignment records processed.\n",
            "6300000 alignment records processed.\n",
            "6400000 alignment records processed.\n",
            "6500000 alignment records processed.\n",
            "6600000 alignment records processed.\n",
            "6700000 alignment records processed.\n",
            "6800000 alignment records processed.\n",
            "6900000 alignment records processed.\n",
            "7000000 alignment records processed.\n",
            "7100000 alignment records processed.\n",
            "7200000 alignment records processed.\n",
            "7300000 alignment records processed.\n",
            "7400000 alignment records processed.\n",
            "7500000 alignment records processed.\n",
            "7600000 alignment records processed.\n",
            "7700000 alignment records processed.\n",
            "7800000 alignment records processed.\n",
            "7900000 alignment records processed.\n",
            "8000000 alignment records processed.\n",
            "8100000 alignment records processed.\n",
            "8200000 alignment records processed.\n",
            "8300000 alignment records processed.\n",
            "8400000 alignment records processed.\n",
            "8500000 alignment records processed.\n",
            "8600000 alignment records processed.\n",
            "8700000 alignment records processed.\n",
            "8800000 alignment records processed.\n",
            "8900000 alignment records processed.\n",
            "9000000 alignment records processed.\n",
            "9100000 alignment records processed.\n",
            "9200000 alignment records processed.\n",
            "9300000 alignment records processed.\n",
            "9400000 alignment records processed.\n",
            "9500000 alignment records processed.\n",
            "9600000 alignment records processed.\n",
            "9700000 alignment records processed.\n",
            "9800000 alignment records processed.\n",
            "9900000 alignment records processed.\n",
            "10000000 alignment records processed.\n",
            "10100000 alignment records processed.\n",
            "10200000 alignment records processed.\n",
            "10300000 alignment records processed.\n",
            "10400000 alignment records processed.\n",
            "10500000 alignment records processed.\n",
            "10600000 alignment records processed.\n",
            "10700000 alignment records processed.\n",
            "10800000 alignment records processed.\n",
            "10900000 alignment records processed.\n",
            "11000000 alignment records processed.\n",
            "11100000 alignment records processed.\n",
            "11200000 alignment records processed.\n",
            "11300000 alignment records processed.\n",
            "11400000 alignment records processed.\n",
            "11500000 alignment records processed.\n",
            "11600000 alignment records processed.\n",
            "11700000 alignment records processed.\n",
            "11800000 alignment records processed.\n",
            "11900000 alignment records processed.\n",
            "12000000 alignment records processed.\n",
            "12100000 alignment records processed.\n",
            "12200000 alignment records processed.\n",
            "12300000 alignment records processed.\n",
            "12400000 alignment records processed.\n",
            "12500000 alignment records processed.\n",
            "12600000 alignment records processed.\n",
            "12700000 alignment records processed.\n",
            "12800000 alignment records processed.\n",
            "12900000 alignment records processed.\n",
            "13000000 alignment records processed.\n",
            "13100000 alignment records processed.\n",
            "13200000 alignment records processed.\n",
            "13300000 alignment records processed.\n",
            "13400000 alignment records processed.\n",
            "13500000 alignment records processed.\n",
            "13600000 alignment records processed.\n",
            "13700000 alignment records processed.\n",
            "13800000 alignment records processed.\n",
            "13900000 alignment records processed.\n",
            "14000000 alignment records processed.\n",
            "14100000 alignment records processed.\n",
            "14200000 alignment records processed.\n",
            "14300000 alignment records processed.\n",
            "14400000 alignment records processed.\n",
            "14500000 alignment records processed.\n",
            "14600000 alignment records processed.\n",
            "14700000 alignment records processed.\n",
            "14800000 alignment records processed.\n",
            "14900000 alignment records processed.\n",
            "15000000 alignment records processed.\n",
            "15100000 alignment records processed.\n",
            "15200000 alignment records processed.\n",
            "15300000 alignment records processed.\n",
            "15400000 alignment records processed.\n",
            "15500000 alignment records processed.\n",
            "15600000 alignment records processed.\n",
            "15700000 alignment records processed.\n",
            "15800000 alignment records processed.\n",
            "15900000 alignment records processed.\n",
            "16000000 alignment records processed.\n",
            "16100000 alignment records processed.\n",
            "16200000 alignment records processed.\n",
            "16300000 alignment records processed.\n",
            "16400000 alignment records processed.\n",
            "16500000 alignment records processed.\n",
            "16600000 alignment records processed.\n",
            "16700000 alignment records processed.\n",
            "16800000 alignment records processed.\n",
            "16900000 alignment records processed.\n",
            "17000000 alignment records processed.\n",
            "17100000 alignment records processed.\n",
            "17200000 alignment records processed.\n",
            "17300000 alignment records processed.\n",
            "17400000 alignment records processed.\n",
            "17500000 alignment records processed.\n",
            "17600000 alignment records processed.\n",
            "17700000 alignment records processed.\n",
            "17800000 alignment records processed.\n",
            "17844858 alignment records processed.\n",
            "\n",
            "real\t18m27.395s\n",
            "user\t18m17.929s\n",
            "sys\t0m7.740s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CHTMa6RlA_m4"
      },
      "source": [
        "* Смотрим сколько чтений не удалось приписать ни одному гену:\n",
        "* `__no_feature 1332692` – столько чтений соответствует участкам генома, где не аннотировано ни одного экзона\n",
        "* `__ambiguous 735108` – столько чтений могут принадлежать разным генам\n",
        "* Более подробно про такие случаи можно посмотреть в описании HTSeq-count - https://htseq.readthedocs.io/en/release_0.11.1/count.html\n",
        "* Итого, общее число чтений, соответствующих хотя бы одному гену равно:\n",
        "17825380 – 1332692 – 735108 = 15757580\n",
        "* Для каждого образца приводим эту статистику в отчете на Github\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wSmB28X89X2x",
        "outputId": "db4738fc-1445-424a-8a4d-c9bfb7db99d0"
      },
      "source": [
        "! grep '^__' SRR3414629.counts"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "__no_feature\t1604107\n",
            "__ambiguous\t722172\n",
            "__too_low_aQual\t0\n",
            "__not_aligned\t0\n",
            "__alignment_not_unique\t0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R1K1_Gy-9YBV",
        "outputId": "a3ab2637-227e-4741-e57a-ee8fd424f9b5"
      },
      "source": [
        "! grep '^__' SRR3414630.counts"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "__no_feature\t1240295\n",
            "__ambiguous\t480520\n",
            "__too_low_aQual\t0\n",
            "__not_aligned\t0\n",
            "__alignment_not_unique\t0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FapRtWuV9YG5",
        "outputId": "a2383798-0c24-4acb-c350-94a0aba3c766"
      },
      "source": [
        "! grep '^__' SRR3414631.counts"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "__no_feature\t1700354\n",
            "__ambiguous\t819740\n",
            "__too_low_aQual\t0\n",
            "__not_aligned\t0\n",
            "__alignment_not_unique\t0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ScXQss099YMj",
        "outputId": "cf309e7c-b5d9-4afc-da01-7923b0081203"
      },
      "source": [
        "! grep '^__' SRR3414635.counts"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "__no_feature\t1392186\n",
            "__ambiguous\t760134\n",
            "__too_low_aQual\t0\n",
            "__not_aligned\t0\n",
            "__alignment_not_unique\t0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HO14QTSB9YRh",
        "outputId": "41334fb7-4a1e-4158-f45a-a2040cd6f320"
      },
      "source": [
        "! grep '^__' SRR3414636.counts"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "__no_feature\t1332692\n",
            "__ambiguous\t735108\n",
            "__too_low_aQual\t0\n",
            "__not_aligned\t0\n",
            "__alignment_not_unique\t0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fvENnVBnisX1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "37c00af5-cfd4-4e99-86cc-2b09787750cb"
      },
      "source": [
        "! grep '^__' SRR3414637.counts"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "__no_feature\t1397650\n",
            "__ambiguous\t710230\n",
            "__too_low_aQual\t0\n",
            "__not_aligned\t0\n",
            "__alignment_not_unique\t0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ruXeKVn_s7NL",
        "outputId": "6d736474-5e8a-466b-d74a-ef62c3fb01fe"
      },
      "source": [
        "print('Общее число чтений для SRR3414629:', 18375888 - 1604107 - 722172)\n",
        "print('Общее число чтений для SRR3414630:', 13186139 - 1240295 - 480520)\n",
        "print('Общее число чтений для SRR3414631:', 20928945 - 1700354 - 819740)\n",
        "print('Общее число чтений для SRR3414635:', 18428317 - 1392186 - 760134)\n",
        "print('Общее число чтений для SRR3414636:', 17825380 - 1332692 - 735108)\n",
        "print('Общее число чтений для SRR3414637:', 17844858 - 1397650 - 710230)"
      ],
      "execution_count": 78,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Общее число чтений для SRR3414629: 16049609\n",
            "Общее число чтений для SRR3414630: 11465324\n",
            "Общее число чтений для SRR3414631: 18408851\n",
            "Общее число чтений для SRR3414635: 16275997\n",
            "Общее число чтений для SRR3414636: 15757580\n",
            "Общее число чтений для SRR3414637: 15736978\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lQ-ryqO0BiDp"
      },
      "source": [
        "* Объединям все файлы .counts по генам в один общий файл `ALL.counts`.\n",
        "* В качестве заголовка для каждого образца указывать не его SRR id, а c1, c2, c3 для контрольных образцов и r1, r2, r3 для перепрограммированных образцов.\n",
        "* Загружаем полученный ALL.counts файл в Github репозиторий"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 235
        },
        "id": "jozSl15s_1qJ",
        "outputId": "7329493e-99ea-4288-c0b5-de8e7717fea5"
      },
      "source": [
        "import pandas as pd\n",
        "j = 0\n",
        "labels = ['c1', 'c2', 'c3', 'r1', 'r2', 'r3']\n",
        "numbers = [35, 36, 37, 29, 30, 31]\n",
        "frames = [0] * len(numbers)\n",
        "for i in numbers:\n",
        "  frames[j] = pd.read_csv('SRR34146{}.counts'.format(i), sep='\\t', names=['feature', labels[j]]).set_index('feature')\n",
        "  j += 1\n",
        "result = pd.concat(frames, axis=1)\n",
        "result.to_csv(path_or_buf='ALL.counts', sep='\\t')\n",
        "result.head()"
      ],
      "execution_count": 81,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>c1</th>\n",
              "      <th>c2</th>\n",
              "      <th>c3</th>\n",
              "      <th>r1</th>\n",
              "      <th>r2</th>\n",
              "      <th>r3</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>feature</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>ENSMUSG00000000001.4</th>\n",
              "      <td>3431</td>\n",
              "      <td>3504</td>\n",
              "      <td>4031</td>\n",
              "      <td>4489</td>\n",
              "      <td>3919</td>\n",
              "      <td>5700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>ENSMUSG00000000003.15</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>ENSMUSG00000000028.15</th>\n",
              "      <td>150</td>\n",
              "      <td>136</td>\n",
              "      <td>152</td>\n",
              "      <td>345</td>\n",
              "      <td>273</td>\n",
              "      <td>468</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>ENSMUSG00000000031.16</th>\n",
              "      <td>55526</td>\n",
              "      <td>48225</td>\n",
              "      <td>56064</td>\n",
              "      <td>64504</td>\n",
              "      <td>33249</td>\n",
              "      <td>64992</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>ENSMUSG00000000037.17</th>\n",
              "      <td>41</td>\n",
              "      <td>44</td>\n",
              "      <td>52</td>\n",
              "      <td>77</td>\n",
              "      <td>68</td>\n",
              "      <td>87</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                          c1     c2     c3     r1     r2     r3\n",
              "feature                                                        \n",
              "ENSMUSG00000000001.4    3431   3504   4031   4489   3919   5700\n",
              "ENSMUSG00000000003.15      0      0      0      0      0      0\n",
              "ENSMUSG00000000028.15    150    136    152    345    273    468\n",
              "ENSMUSG00000000031.16  55526  48225  56064  64504  33249  64992\n",
              "ENSMUSG00000000037.17     41     44     52     77     68     87"
            ]
          },
          "metadata": {},
          "execution_count": 81
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mhArj1uJt3YK"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}